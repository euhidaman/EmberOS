"""
Agent Planner for EmberOS.

Creates execution plans based on user commands and available tools,
then synthesizes responses from execution results.
"""

from __future__ import annotations

import json
import logging
from typing import Any, Optional
from dataclasses import dataclass, field, asdict
from datetime import datetime

from emberos.daemon.llm_orchestrator import LLMOrchestrator, CompletionRequest

logger = logging.getLogger(__name__)


@dataclass
class ToolCall:
    """A single tool invocation in a plan."""
    tool: str
    args: dict[str, Any]
    description: Optional[str] = None
    depends_on: Optional[list[int]] = None

    def to_dict(self) -> dict:
        return asdict(self)


@dataclass
class ExecutionPlan:
    """An execution plan generated by the planner."""
    reasoning: str
    steps: list[ToolCall]
    requires_confirmation: bool = False
    confirmation_message: Optional[str] = None
    estimated_duration: Optional[int] = None  # seconds
    risk_level: str = "low"  # low, medium, high

    def to_dict(self) -> dict:
        return {
            "reasoning": self.reasoning,
            "steps": [step.to_dict() for step in self.steps],
            "requires_confirmation": self.requires_confirmation,
            "confirmation_message": self.confirmation_message,
            "estimated_duration": self.estimated_duration,
            "risk_level": self.risk_level
        }

    @classmethod
    def from_dict(cls, data: dict) -> ExecutionPlan:
        steps = [ToolCall(**step) for step in data.get("steps", data.get("plan", []))]
        return cls(
            reasoning=data.get("reasoning", ""),
            steps=steps,
            requires_confirmation=data.get("requires_confirmation", False),
            confirmation_message=data.get("confirmation_message"),
            estimated_duration=data.get("estimated_duration"),
            risk_level=data.get("risk_level", "low")
        )


@dataclass
class ToolResult:
    """Result from executing a tool."""
    tool: str
    success: bool
    result: Any
    error: Optional[str] = None
    duration_ms: int = 0

    def to_dict(self) -> dict:
        return asdict(self)


SYSTEM_PROMPT = """You are Ember-VLM, a local AI assistant running on the user's machine.
You have access to:
{tools_json}

Context:
{context_json}

Keep responses concise. If asked about your model/identity, say you are 'Ember-VLM'."""


PLANNING_PROMPT = """User request: {user_message}

Based on the user's request and available tools, create an execution plan.

Respond with a JSON object in this exact format:
{{
  "reasoning": "Your step-by-step thinking about how to accomplish this task",
  "plan": [
    {{"tool": "tool.name", "args": {{"param1": "value1"}}, "description": "What this step does"}}
  ],
  "requires_confirmation": true/false,
  "confirmation_message": "Message to show user if confirmation needed",
  "risk_level": "low/medium/high"
}}

Important:
- Use actual tool names from the available tools list
- Include all required parameters for each tool
- Set requires_confirmation=true for: file deletion, system changes, bulk operations
- Use $result[N] to reference output from step N (0-indexed)"""


SYNTHESIS_PROMPT = """Original request: {user_message}

Execution plan:
{plan_json}

Execution results:
{results_json}

Provide a brief, helpful response (2-3 sentences max):
- Summarize what was accomplished
- Highlight key findings
- Mention any issues

Keep it concise and natural."""


class AgentPlanner:
    """
    Plans and synthesizes agent actions.

    Uses the LLM to:
    1. Create execution plans from natural language
    2. Validate plans against tool schemas
    3. Synthesize user-friendly responses from results
    """

    def __init__(self, llm: LLMOrchestrator, tool_registry):
        self.llm = llm
        self.tool_registry = tool_registry
        # Conversation history for context (sliding window)
        self._conversation_history: list[dict] = []
        self._max_history_turns = 50  # Keep last 50 turns (25 user + 25 assistant) - much longer context

    def _add_to_history(self, role: str, content: str) -> None:
        """Add a message to conversation history with sliding window."""
        self._conversation_history.append({
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat()
        })

        # Apply sliding window: keep only last N turns
        if len(self._conversation_history) > self._max_history_turns * 2:
            # Keep last N turns (each turn = user + assistant)
            self._conversation_history = self._conversation_history[-(self._max_history_turns * 2):]
            logger.info(f"Trimmed conversation history to last {self._max_history_turns} turns")

    def _get_context_size(self) -> int:
        """Estimate context size in tokens (rough approximation)."""
        total_chars = sum(len(msg["content"]) for msg in self._conversation_history)
        # Rough estimate: 1 token ≈ 4 characters
        return total_chars // 4

    def _build_conversation_context(self) -> list[dict]:
        """Build conversation context from history."""
        context_size = self._get_context_size()
        if context_size > 15000:  # Increased from 3000 to 15000 for longer conversations
            logger.warning(f"Context size is {context_size} tokens - this may cause slowdowns")

        return self._conversation_history.copy()

    def clear_history(self) -> None:
        """Clear conversation history (useful for starting fresh)."""
        logger.info("Clearing conversation history")
        self._conversation_history = []

    async def create_plan(
        self,
        user_message: str,
        context: Any
    ) -> ExecutionPlan:
        """
        Create an execution plan for a user request.

        Args:
            user_message: The user's natural language request
            context: Current system context

        Returns:
            ExecutionPlan with steps to execute
        """
        # Add user message to history
        self._add_to_history("user", user_message)

        # Log context size
        context_size = self._get_context_size()
        logger.info(f"Current context size: ~{context_size} tokens")

        # Get tool schemas
        # tools = self.tool_registry.get_all_schemas()
        # tools_json = json.dumps(tools, indent=2)
        
        # OPTIMIZATION: Only send tool names to save tokens for BitNet CPU
        tools_list = [t["name"] for t in self.tool_registry.list_tools()]
        tools_json = ", ".join(tools_list)

        # Format context
        context_dict = context if isinstance(context, dict) else asdict(context)
        context_json = json.dumps(context_dict, indent=2)

        # Build system prompt
        system_prompt = SYSTEM_PROMPT.format(
            tools_json=tools_json,
            context_json=context_json
        )

        # Build planning prompt
        planning_prompt = PLANNING_PROMPT.format(user_message=user_message)

        # Use conversation history for context
        conversation_context = self._build_conversation_context()
        messages = conversation_context + [
            {"role": "user", "content": planning_prompt}
        ]

        try:
            response = await self.llm.complete_chat(
                messages=messages,
                system_prompt=system_prompt,
                temperature=0.1,
                max_tokens=2048
            )

            # Parse response
            content = response.content.strip()

            # Extract JSON from response
            plan_data = self._extract_json(content)

            if not plan_data:
                # Fallback: create a simple response plan
                return ExecutionPlan(
                    reasoning="Unable to parse plan, providing direct response",
                    steps=[],
                    requires_confirmation=False
                )

            plan = ExecutionPlan.from_dict(plan_data)

            # Validate and adjust plan
            plan = self._validate_plan(plan)

            return plan

        except Exception as e:
            logger.exception(f"Error creating plan: {e}")
            return ExecutionPlan(
                reasoning=f"Error creating plan: {e}",
                steps=[],
                requires_confirmation=False
            )

    def _extract_json(self, content: str) -> Optional[dict]:
        """Extract JSON from LLM response."""
        # Try direct parse
        try:
            return json.loads(content)
        except json.JSONDecodeError:
            pass

        # Try to find JSON in content
        import re
        json_match = re.search(r'\{[\s\S]*\}', content)
        if json_match:
            try:
                return json.loads(json_match.group())
            except json.JSONDecodeError:
                pass

        # Try removing markdown code blocks
        if "```" in content:
            lines = content.split("\n")
            json_lines = []
            in_block = False
            for line in lines:
                if line.strip().startswith("```"):
                    in_block = not in_block
                elif in_block:
                    json_lines.append(line)

            if json_lines:
                try:
                    return json.loads("\n".join(json_lines))
                except json.JSONDecodeError:
                    pass

        return None

    def _validate_plan(self, plan: ExecutionPlan) -> ExecutionPlan:
        """Validate and adjust execution plan."""
        valid_steps = []

        for step in plan.steps:
            # Check if tool exists
            if self.tool_registry.has_tool(step.tool):
                # Validate parameters against schema
                schema = self.tool_registry.get_schema(step.tool)
                if schema:
                    # Basic validation - could be more thorough
                    valid_steps.append(step)
                else:
                    valid_steps.append(step)
            else:
                logger.warning(f"Unknown tool in plan: {step.tool}")

        plan.steps = valid_steps

        # Check if confirmation is needed
        destructive_tools = [
            "filesystem.delete", "filesystem.move", "filesystem.write",
            "system.shutdown", "system.restart", "system.update"
        ]

        for step in plan.steps:
            if step.tool in destructive_tools:
                plan.requires_confirmation = True
                if not plan.confirmation_message:
                    plan.confirmation_message = f"This action will use {step.tool}. Continue?"
                break

        return plan

    async def synthesize_response(
        self,
        user_message: str,
        plan: ExecutionPlan,
        results: list[ToolResult]
    ) -> str:
        """
        Synthesize a user-friendly response from execution results.

        Args:
            user_message: Original user request
            plan: The execution plan that was followed
            results: Results from each tool execution

        Returns:
            Natural language response for the user
        """
        # If no tools were executed, generate direct response
        if not results:
            # Use conversation history for better context
            conversation_context = self._build_conversation_context()

            # Add system prompt with model identity and concise instruction
            system_message = {
                "role": "system",
                "content": (
                    "You are Ember-VLM, a local AI assistant. "
                    "Keep responses concise and to the point. "
                    "If asked about your model/identity, say you are 'Ember-VLM'."
                )
            }

            messages = [system_message] + conversation_context + [{"role": "user", "content": user_message}]

            response = await self.llm.complete_chat(
                messages=messages,
                temperature=0.3,
                max_tokens=256  # Reduced from 1024 for concise responses
            )
            assistant_response = response.content.strip()

            # Add to history
            self._add_to_history("assistant", assistant_response)

            return assistant_response

        # Build synthesis prompt
        results_json = json.dumps([r.to_dict() for r in results], indent=2)

        synthesis_prompt = SYNTHESIS_PROMPT.format(
            user_message=user_message,
            plan_json=json.dumps(plan.to_dict(), indent=2),
            results_json=results_json
        )

        messages = [{"role": "user", "content": synthesis_prompt}]

        try:
            response = await self.llm.complete_chat(
                messages=messages,
                temperature=0.3,
                max_tokens=256  # Reduced from 1024 for concise responses
            )
            content = response.content.strip() if response and response.content else ""
            
            if not content:
                content = "✓ Task completed successfully (No description provided by Agent)."

            # Add to history
            self._add_to_history("assistant", content)

            return content

        except Exception as e:
            logger.exception(f"Error synthesizing response: {e}")

            # Fallback: basic result summary
            success_count = sum(1 for r in results if r.success)
            total_count = len(results)

            if success_count == total_count:
                fallback = f"✓ Completed {total_count} operation(s) successfully."
            else:
                fallback = f"Completed {success_count}/{total_count} operations. Some errors occurred."

            self._add_to_history("assistant", fallback)
            return fallback

    async def refine_plan(
        self,
        plan: ExecutionPlan,
        error: str,
        context: Any
    ) -> ExecutionPlan:
        """
        Refine a plan based on execution errors.

        Args:
            plan: The original plan
            error: Error that occurred
            context: Current system context

        Returns:
            Refined execution plan
        """
        refinement_prompt = f"""The following plan encountered an error:

Plan: {json.dumps(plan.to_dict(), indent=2)}

Error: {error}

Please provide a refined plan that addresses this error. Respond with the same JSON format."""

        messages = [{"role": "user", "content": refinement_prompt}]

        try:
            response = await self.llm.complete_chat(
                messages=messages,
                temperature=0.1,
                max_tokens=2048
            )

            plan_data = self._extract_json(response.content)
            if plan_data:
                return ExecutionPlan.from_dict(plan_data)

        except Exception as e:
            logger.exception(f"Error refining plan: {e}")

        return plan

