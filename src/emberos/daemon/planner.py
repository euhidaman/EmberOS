"""
Agent Planner for EmberOS.

Creates execution plans based on user commands and available tools,
then synthesizes responses from execution results.
"""

from __future__ import annotations

import json
import logging
from typing import Any, Optional
from dataclasses import dataclass, field, asdict
from datetime import datetime

from emberos.daemon.llm_orchestrator import LLMOrchestrator, CompletionRequest

logger = logging.getLogger(__name__)


@dataclass
class ToolCall:
    """A single tool invocation in a plan."""
    tool: str
    args: dict[str, Any]
    description: Optional[str] = None
    depends_on: Optional[list[int]] = None

    def to_dict(self) -> dict:
        return asdict(self)


@dataclass
class ExecutionPlan:
    """An execution plan generated by the planner."""
    reasoning: str
    steps: list[ToolCall]
    requires_confirmation: bool = False
    confirmation_message: Optional[str] = None
    estimated_duration: Optional[int] = None  # seconds
    risk_level: str = "low"  # low, medium, high

    def to_dict(self) -> dict:
        return {
            "reasoning": self.reasoning,
            "steps": [step.to_dict() for step in self.steps],
            "requires_confirmation": self.requires_confirmation,
            "confirmation_message": self.confirmation_message,
            "estimated_duration": self.estimated_duration,
            "risk_level": self.risk_level
        }

    @classmethod
    def from_dict(cls, data: dict) -> ExecutionPlan:
        steps = [ToolCall(**step) for step in data.get("steps", data.get("plan", []))]
        return cls(
            reasoning=data.get("reasoning", ""),
            steps=steps,
            requires_confirmation=data.get("requires_confirmation", False),
            confirmation_message=data.get("confirmation_message"),
            estimated_duration=data.get("estimated_duration"),
            risk_level=data.get("risk_level", "low")
        )


@dataclass
class ToolResult:
    """Result from executing a tool."""
    tool: str
    success: bool
    result: Any
    error: Optional[str] = None
    duration_ms: int = 0

    def to_dict(self) -> dict:
        return asdict(self)


SYSTEM_PROMPT = """You are Ember-VLM, a local AI assistant running on the user's machine.

IMPORTANT: You MUST use tools to get factual information. NEVER guess or hallucinate.

When asked about:
- Current directory → Use tools to find it
- Files in a folder → Use filesystem.list tool
- System info → Use system.info tool
- Running processes → Use system.processes tool

You have access to:
{tools_json}

Context:
{context_json}

Keep responses concise. If asked about your model/identity, say you are 'Ember-VLM'.

REMEMBER: Use tools for facts. Don't make up information."""


PLANNING_PROMPT = """User request: {user_message}

Based on the user's request and available tools, create an execution plan.

IMPORTANT: Use tools to get real information. Examples:
- "which folder am I in?" → Use tool to get current directory
- "what files in Downloads?" → Use filesystem.list on ~/Downloads
- "what's my system info?" → Use system.info tool

NEVER create an empty plan for factual queries. Always use appropriate tools.

Respond with a JSON object in this exact format:
{{
  "reasoning": "Your step-by-step thinking about how to accomplish this task",
  "plan": [
    {{"tool": "tool.name", "args": {{"param1": "value1"}}, "description": "What this step does"}}
  ],
  "requires_confirmation": true/false,
  "confirmation_message": "Message to show user if confirmation needed",
  "risk_level": "low/medium/high"
}}

Important:
- Use actual tool names from the available tools list
- Include all required parameters for each tool
- Set requires_confirmation=true for: file deletion, system changes, bulk operations
- Use $result[N] to reference output from step N (0-indexed)
- For factual queries (folders, files, system info), you MUST use tools"""


SYNTHESIS_PROMPT = """Original request: {user_message}

Execution plan:
{plan_json}

Execution results:
{results_json}

Provide a brief, helpful response (2-3 sentences max):
- Summarize what was accomplished
- Highlight key findings
- Mention any issues

Keep it concise and natural."""


class AgentPlanner:
    """
    Plans and synthesizes agent actions.

    Uses the LLM to:
    1. Create execution plans from natural language
    2. Validate plans against tool schemas
    3. Synthesize user-friendly responses from results
    """

    def __init__(self, llm: LLMOrchestrator, tool_registry):
        self.llm = llm
        self.tool_registry = tool_registry
        # Conversation history for context (sliding window)
        self._conversation_history: list[dict] = []
        self._max_history_turns = 50  # Keep last 50 turns (25 user + 25 assistant) - much longer context

    def _add_to_history(self, role: str, content: str) -> None:
        """Add a message to conversation history with sliding window."""
        self._conversation_history.append({
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat()
        })

        # Apply sliding window: keep only last N turns
        if len(self._conversation_history) > self._max_history_turns * 2:
            # Keep last N turns (each turn = user + assistant)
            self._conversation_history = self._conversation_history[-(self._max_history_turns * 2):]
            logger.info(f"Trimmed conversation history to last {self._max_history_turns} turns")

    def _get_context_size(self) -> int:
        """Estimate context size in tokens (rough approximation)."""
        total_chars = sum(len(msg["content"]) for msg in self._conversation_history)
        # Rough estimate: 1 token ≈ 4 characters
        return total_chars // 4

    def _build_conversation_context(self) -> list[dict]:
        """Build conversation context from history."""
        context_size = self._get_context_size()
        if context_size > 15000:  # Increased from 3000 to 15000 for longer conversations
            logger.warning(f"Context size is {context_size} tokens - this may cause slowdowns")

        return self._conversation_history.copy()

    def clear_history(self) -> None:
        """Clear conversation history (useful for starting fresh)."""
        logger.info("Clearing conversation history")
        self._conversation_history = []

    def _correct_typos(self, text: str) -> tuple[str, bool]:
        """
        Attempt to correct common typos and misspellings.

        Returns:
            Tuple of (corrected_text, was_corrected)
        """
        original = text
        corrected = text

        # Common word corrections (misspelling -> correct)
        common_corrections = {
            # Question words
            "wat": "what", "waht": "what", "wht": "what", "whta": "what",
            "wher": "where", "whre": "where", "wehre": "where", "whrere": "where",
            "wich": "which", "whcih": "which", "whihc": "which",
            "hwo": "how", "hw": "how", "howw": "how",
            "whn": "when", "wehn": "when", "whne": "when",
            "whi": "why", "whhy": "why",

            # Common verbs
            "ar": "are", "aer": "are", "rae": "are",
            "si": "is", "iss": "is",
            "cna": "can", "acn": "can",
            "cn": "can",
            "woudl": "would", "wuold": "would", "wold": "would",
            "cuold": "could", "coudl": "could", "coud": "could",
            "shoudl": "should", "shuold": "should", "shoud": "should",
            "hvae": "have", "ahve": "have", "hav": "have",
            "dose": "does", "deos": "does",
            "dont": "don't", "dnt": "don't", "donot": "do not",
            "cant": "can't", "cnat": "can't", "cannot": "can not",
            "wont": "won't",
            "im": "i'm", "iam": "i am",
            "youre": "you're", "your're": "you're",
            "theyre": "they're", "thier": "their",
            "teh": "the", "hte": "the", "th": "the",

            # File system related
            "fils": "files", "fiel": "file", "fiels": "files", "filles": "files",
            "floder": "folder", "fodler": "folder", "foldr": "folder", "flder": "folder",
            "direcotry": "directory", "directroy": "directory", "diretory": "directory",
            "downlods": "downloads", "donwloads": "downloads", "downlaods": "downloads",
            "documets": "documents", "docuemnts": "documents", "documetns": "documents",
            "destop": "desktop", "dekstop": "desktop", "destkop": "desktop",
            "picutres": "pictures", "picturs": "pictures", "pictrues": "pictures",
            "vdieos": "videos", "vidoes": "videos", "viedos": "videos",
            "muisc": "music", "musc": "music", "musci": "music",

            # Actions
            "crate": "create", "craete": "create", "creat": "create",
            "delte": "delete", "deleet": "delete", "delet": "delete",
            "remvoe": "remove", "reomve": "remove", "remov": "remove",
            "mvoe": "move", "moev": "move",
            "cpoy": "copy", "coyp": "copy",
            "serach": "search", "seach": "search", "saerch": "search",
            "fnd": "find", "fidn": "find", "fnid": "find",
            "opne": "open", "oepn": "open",
            "lsit": "list", "lits": "list", "lis": "list",
            "shwo": "show", "hsow": "show", "sohw": "show",
            "raed": "read", "reda": "read",
            "wrtie": "write", "wirte": "write", "writ": "write",
            "renam": "rename", "renaem": "rename",
            "orgnaize": "organize", "organzie": "organize", "oragnize": "organize",

            # Common nouns
            "spredsheet": "spreadsheet", "spreadhseet": "spreadsheet", "spreadshet": "spreadsheet",
            "bduget": "budget", "budegt": "budget",
            "systme": "system", "sysetm": "system", "sysem": "system",
            "procss": "process", "porcess": "process",
            "memroy": "memory", "memoyr": "memory",
            "infromation": "information", "informaiton": "information", "info": "information",

            # Pronouns
            "yuo": "you", "yoi": "you", "uyo": "you",
            "i": "I",  # Capitalize I
            "mee": "me", "em": "me",
            "thsi": "this", "htis": "this", "tihs": "this",
            "taht": "that", "htat": "that",
            "thees": "these", "tehse": "these",
            "tehre": "there", "theer": "there", "ther": "there",
            "heer": "here", "hre": "here", "hrer": "here",

            # Misc
            "abuot": "about", "abotu": "about", "baout": "about",
            "wiht": "with", "wtih": "with", "iwth": "with",
            "fomr": "from", "form": "from", "frm": "from",
            "anythign": "anything", "anythin": "anything",
            "somethign": "something", "somethin": "something",
            "nothign": "nothing", "nothin": "nothing",
            "plase": "please", "pls": "please", "plz": "please",
            "thnk": "think", "thikn": "think",
            "knwo": "know", "konw": "know", "kno": "know",
            "becuase": "because", "becasue": "because", "bcause": "because",
        }

        # Apply word-level corrections
        words = corrected.split()
        corrected_words = []

        for word in words:
            # Check if word needs correction
            clean_word = word.strip(".,?!;:'\"")
            punctuation = word[len(clean_word):] if len(word) > len(clean_word) else ""

            if clean_word in common_corrections:
                corrected_words.append(common_corrections[clean_word] + punctuation)
            else:
                corrected_words.append(word)

        corrected = " ".join(corrected_words)

        # Fix common phrase patterns
        phrase_corrections = [
            # "where ar you" -> "where are you"
            (r"\bwhere\s+ar\s+you\b", "where are you"),
            (r"\bwhat\s+ar\s+you\b", "what are you"),
            (r"\bwho\s+ar\s+you\b", "who are you"),
            (r"\bhow\s+ar\s+you\b", "how are you"),
            # "wat can you do" -> "what can you do"
            (r"\bwat\s+can\b", "what can"),
            (r"\bwat\s+is\b", "what is"),
            (r"\bwat\s+are\b", "what are"),
            # Double letters
            (r"\bhelllo\b", "hello"),
            (r"\bhiii\b", "hi"),
            # Missing spaces
            (r"\bwhatis\b", "what is"),
            (r"\bwhereis\b", "where is"),
            (r"\bhowto\b", "how to"),
            (r"\bcantyou\b", "can't you"),
            (r"\bdoyou\b", "do you"),
            (r"\bcanyou\b", "can you"),
            # "u" as "you"
            (r"\bu\b", "you"),
            (r"\br\b", "are"),
            (r"\by\b", "why"),
        ]

        import re
        for pattern, replacement in phrase_corrections:
            corrected = re.sub(pattern, replacement, corrected, flags=re.IGNORECASE)

        was_corrected = (corrected != original)
        return corrected, was_corrected

    def _is_too_garbled(self, text: str) -> bool:
        """
        Check if the text is too garbled to understand.

        Returns True if we should ask the user to rephrase.
        """
        # Very short messages are usually fine
        if len(text) < 5:
            return False

        words = text.split()

        # If message has very few recognizable words, it's garbled
        # Check against a list of common English words
        common_words = {
            "the", "a", "an", "is", "are", "was", "were", "be", "been", "being",
            "have", "has", "had", "do", "does", "did", "will", "would", "could",
            "should", "may", "might", "must", "can", "shall",
            "i", "you", "he", "she", "it", "we", "they", "me", "him", "her", "us", "them",
            "my", "your", "his", "its", "our", "their", "mine", "yours", "ours", "theirs",
            "this", "that", "these", "those", "what", "which", "who", "whom", "whose",
            "where", "when", "why", "how",
            "and", "or", "but", "if", "then", "else", "because", "so", "for", "nor",
            "in", "on", "at", "to", "from", "by", "with", "about", "into", "through",
            "not", "no", "yes", "here", "there", "now", "then",
            "all", "some", "any", "many", "much", "more", "most", "few", "less", "least",
            "just", "only", "also", "very", "too", "quite", "really", "still",
            "new", "old", "good", "bad", "great", "first", "last", "long", "short",
            "file", "files", "folder", "folders", "directory", "desktop", "downloads",
            "documents", "pictures", "videos", "music", "home",
            "create", "delete", "move", "copy", "rename", "find", "search", "list",
            "show", "open", "read", "write", "help", "please", "thanks",
            "hello", "hi", "hey", "bye", "ok", "okay", "sure", "yes", "no",
        }

        # Count recognizable words
        recognizable_count = 0
        for word in words:
            clean_word = word.strip(".,?!;:'\"").lower()
            if clean_word in common_words or len(clean_word) <= 2:
                recognizable_count += 1

        # If less than 30% of words are recognizable, it's garbled
        if len(words) > 3 and recognizable_count / len(words) < 0.3:
            return True

        # Check for excessive repeated characters (like "aaaaaaaa")
        import re
        if re.search(r'(.)\1{4,}', text):  # 5+ repeated chars
            return True

        # Check for no vowels (likely keyboard mashing)
        vowels = set('aeiouAEIOU')
        has_vowel = any(c in vowels for c in text if c.isalpha())
        if len(text) > 5 and not has_vowel:
            return True

        return False

    async def create_plan(
        self,
        user_message: str,
        context: Any
    ) -> ExecutionPlan:
        """
        Create an execution plan for a user request.

        Args:
            user_message: The user's natural language request
            context: Current system context

        Returns:
            ExecutionPlan with steps to execute
        """
        # Add user message to history
        self._add_to_history("user", user_message)

        # =====================================================
        # STEP 0: TYPO CORRECTION AND FUZZY MATCHING
        # Attempt to understand user intent despite typos/misspellings
        # =====================================================

        original_message = user_message
        normalized = user_message.strip().lower()

        # Apply typo corrections
        corrected_message, was_corrected = self._correct_typos(normalized)
        if was_corrected:
            logger.info(f"[PLANNER] Corrected typos: '{normalized}' -> '{corrected_message}'")
            normalized = corrected_message

        # Check if message is too garbled to understand
        if self._is_too_garbled(normalized):
            logger.warning(f"[PLANNER] Message too garbled to understand: '{original_message}'")
            return ExecutionPlan(
                reasoning="Message unclear - ask user to rephrase.",
                steps=[],
                requires_confirmation=False
            )

        # =====================================================
        # STEP 1: DIRECT RESPONSE QUERIES (NO TOOLS NEEDED)
        # These are general knowledge or identity questions
        # =====================================================

        # --- IDENTITY QUESTIONS ---
        identity_phrases = [
            "what are you", "who are you", "what model", "which model",
            "what llm", "what ai", "your name", "tell me about yourself",
            "introduce yourself", "are you gpt", "are you chatgpt",
            "are you claude", "are you llama", "what can you do",
            "your capabilities", "help me"
        ]
        if any(phrase in normalized for phrase in identity_phrases):
            # Return empty plan - will trigger direct LLM response
            return ExecutionPlan(
                reasoning="Identity/capability question - respond directly without tools.",
                steps=[],
                requires_confirmation=False
            )

        # --- GENERAL KNOWLEDGE QUESTIONS ---
        # These don't need tools - they're just knowledge questions
        general_knowledge_indicators = [
            # Question words that typically indicate general knowledge
            "does a ", "is a ", "are there ", "what is a ", "what are ",
            "how does ", "how do ", "why is ", "why do ", "why are ",
            "can a ", "could a ", "would a ", "should a ",
            "explain ", "tell me about ", "describe ",
            "what's the difference", "compare ", "versus ",
            # Math and logic
            "calculate ", "compute ", "what is ", "how many ", "how much ",
            # Facts
            "who invented", "who created", "who discovered", "when was ",
            "where is ", "what year ", "how old is ",
            # Concepts
            "define ", "meaning of ", "what does ", "definition of "
        ]

        # Check if this is a general knowledge question (not about files/system)
        system_indicators = [
            "file", "folder", "directory", "download", "document", "desktop",
            "system", "process", "memory", "disk", "cpu", "computer",
            "create", "delete", "move", "copy", "rename", "open", "read",
            "my ", "this ", "here", "current"
        ]

        is_general_knowledge = any(indicator in normalized for indicator in general_knowledge_indicators)
        is_system_related = any(indicator in normalized for indicator in system_indicators)

        if is_general_knowledge and not is_system_related:
            # This is a general knowledge question - respond directly
            return ExecutionPlan(
                reasoning="General knowledge question - respond directly using LLM knowledge.",
                steps=[],
                requires_confirmation=False
            )

        # --- SIMPLE CONVERSATIONAL QUERIES ---
        simple_phrases = [
            "hello", "hi", "hey", "good morning", "good afternoon", "good evening",
            "thanks", "thank you", "bye", "goodbye", "okay", "ok", "yes", "no",
            "cool", "nice", "great", "awesome", "sure", "alright"
        ]
        if normalized.strip() in simple_phrases or len(normalized.split()) <= 2:
            # Very short or greeting - respond directly
            if not any(word in normalized for word in ["list", "show", "find", "create", "delete", "open"]):
                return ExecutionPlan(
                    reasoning="Simple greeting or acknowledgment - respond directly.",
                    steps=[],
                    requires_confirmation=False
                )

        # =====================================================
        # STEP 2: FILESYSTEM CRUD RULE-BASED ROUTING
        # These require tools to interact with the system
        # =====================================================

        # --- WORKING DIRECTORY ---
        if any(phrase in normalized for phrase in [
            "which folder am i in",
            "where am i",
            "current directory",
            "working directory",
            "which folder are you in",
            "where are you",
            "pwd",
            "cwd"
        ]):
            return ExecutionPlan(
                reasoning="Use system.getcwd to return the current working directory.",
                steps=[ToolCall(tool="system.getcwd", args={}, description="Get current working directory")],
                requires_confirmation=False
            )

        # --- WHAT FOLDERS CAN YOU SEE ---
        if any(phrase in normalized for phrase in [
            "which folders can you see",
            "what folders can you see",
            "what folders do you see",
            "show me folders",
            "list folders",
            "available folders",
            "what folders are there",
            "what directories",
            "list my folders"
        ]):
            return ExecutionPlan(
                reasoning="List folders in user's home directory.",
                steps=[ToolCall(
                    tool="filesystem.list_enhanced",
                    args={"path": "~", "page_size": 20},
                    description="List folders in home directory"
                )],
                requires_confirmation=False
            )

        # --- PAGINATION CONTINUATION ---
        if any(phrase in normalized for phrase in [
            "show more",
            "list more",
            "continue",
            "next page",
            "more items",
            "more files",
            "keep going",
            "yes, show more",
            "yes show more"
        ]) and "stop" not in normalized:
            # Get last pagination session from context if available
            return ExecutionPlan(
                reasoning="Continue listing from previous pagination state.",
                steps=[ToolCall(
                    tool="filesystem.list_enhanced",
                    args={"path": ".", "continue_pagination": True, "page_size": 10},
                    description="Show next page of directory listing"
                )],
                requires_confirmation=False
            )

        # --- STOP PAGINATION ---
        if any(phrase in normalized for phrase in [
            "stop",
            "enough",
            "that's all",
            "no more",
            "cancel",
            "don't show more"
        ]):
            return ExecutionPlan(
                reasoning="User requested to stop listing.",
                steps=[],
                requires_confirmation=False
            )

        # --- DIRECTORY LISTING (Enhanced matching) ---
        # Common patterns: "what files in X", "show X folder", "list X", "what's in X"
        list_patterns = [
            r"(?:what|which|show|list|display|see)\s*(?:files?|folders?|items?|contents?)?\s*(?:are\s*)?(?:in|inside|on|at)?\s*(?:my\s*)?(\w+)",
            r"(?:what's|whats)\s*(?:in|inside)\s*(?:my\s*)?(\w+)",
            r"(?:list|show|display)\s*(?:my\s*)?(\w+)\s*(?:folder|directory)?",
            r"(?:open|go to)\s*(?:my\s*)?(\w+)",
        ]

        folder_aliases = {
            "desktop": "~/Desktop",
            "downloads": "~/Downloads",
            "documents": "~/Documents",
            "pictures": "~/Pictures",
            "videos": "~/Videos",
            "music": "~/Music",
            "home": "~",
        }

        # Check for explicit folder names in query
        for folder_name, folder_path in folder_aliases.items():
            if folder_name in normalized and any(word in normalized for word in [
                "files", "file", "list", "what", "show", "folder", "in", "inside", "open"
            ]):
                return ExecutionPlan(
                    reasoning=f"List files in {folder_name} directory.",
                    steps=[ToolCall(
                        tool="filesystem.list_enhanced",
                        args={"path": folder_path, "page_size": 10},
                        description=f"List files in {folder_name}"
                    )],
                    requires_confirmation=False
                )

        # Generic "list here" or "what files here"
        if any(phrase in normalized for phrase in [
            "what files here",
            "what's here",
            "whats here",
            "list here",
            "files here",
            "show files",
            "list files"
        ]) and not any(folder in normalized for folder in folder_aliases.keys()):
            return ExecutionPlan(
                reasoning="List files in current directory.",
                steps=[ToolCall(
                    tool="filesystem.list_enhanced",
                    args={"path": ".", "page_size": 10},
                    description="List files in current directory"
                )],
                requires_confirmation=False
            )

        # --- FILE SEARCH ---
        search_indicators = ["find", "search", "locate", "where is", "look for"]
        if any(indicator in normalized for indicator in search_indicators):
            import re
            # Try to extract filename from query
            search_match = re.search(
                r"(?:find|search|locate|look\s*for|where\s*is)\s*(?:my\s*)?(?:a\s*)?(?:file\s*)?(?:called\s*|named\s*)?[\"']?(\S+)[\"']?",
                normalized
            )
            if search_match:
                query = search_match.group(1).strip("\"'")
                return ExecutionPlan(
                    reasoning=f"Search for file matching '{query}'.",
                    steps=[ToolCall(
                        tool="filesystem.find",
                        args={"query": query, "path": "~", "max_results": 20},
                        description=f"Find files matching '{query}'"
                    )],
                    requires_confirmation=False
                )

        # --- FILE CREATION ---
        create_indicators = ["create", "make", "new", "generate"]
        file_types = {
            "spreadsheet": ("filesystem.create_spreadsheet", {"path": "new_spreadsheet.csv", "template": "blank"}),
            "budget": ("filesystem.create_spreadsheet", {"path": "budget.csv", "template": "budget"}),
            "csv": ("filesystem.create_spreadsheet", {"path": "data.csv", "template": "blank"}),
            "python": ("filesystem.create_file", {"path": "script.py", "template": "python"}),
            "script": ("filesystem.create_file", {"path": "script.py", "template": "python"}),
            "javascript": ("filesystem.create_file", {"path": "script.js", "template": "javascript"}),
            "js": ("filesystem.create_file", {"path": "script.js", "template": "javascript"}),
            "html": ("filesystem.create_file", {"path": "page.html", "template": "html"}),
            "webpage": ("filesystem.create_file", {"path": "page.html", "template": "html"}),
            "markdown": ("filesystem.create_file", {"path": "document.md", "template": "markdown"}),
            "md": ("filesystem.create_file", {"path": "document.md", "template": "markdown"}),
            "readme": ("filesystem.create_file", {"path": "README.md", "template": "readme"}),
            "text": ("filesystem.create_file", {"path": "document.txt", "template": "blank"}),
            "txt": ("filesystem.create_file", {"path": "document.txt", "template": "blank"}),
            "file": ("filesystem.create_file", {"path": "new_file.txt", "template": "blank"}),
            "json": ("filesystem.create_file", {"path": "data.json", "template": "json"}),
            "yaml": ("filesystem.create_file", {"path": "config.yaml", "template": "yaml"}),
            "folder": ("filesystem.create_directory", {"path": "new_folder"}),
            "directory": ("filesystem.create_directory", {"path": "new_folder"}),
        }

        if any(indicator in normalized for indicator in create_indicators):
            import re
            # Try to extract filename and file type
            name_match = re.search(r"(?:called|named|with\s*(?:the\s*)?name)\s*[\"']?(\S+)[\"']?", normalized)

            for file_type, (tool, default_args) in file_types.items():
                if file_type in normalized:
                    args = default_args.copy()

                    # Extract custom name if provided
                    if name_match:
                        custom_name = name_match.group(1).strip("\"'")
                        # Add appropriate extension if not present
                        if file_type in ["spreadsheet", "budget", "csv"]:
                            if not custom_name.endswith(".csv"):
                                custom_name += ".csv"
                        elif file_type in ["python", "script"]:
                            if not custom_name.endswith(".py"):
                                custom_name += ".py"
                        args["path"] = f"~/{custom_name}"

                    return ExecutionPlan(
                        reasoning=f"Create a new {file_type} file.",
                        steps=[ToolCall(tool=tool, args=args, description=f"Create {file_type} file")],
                        requires_confirmation=False
                    )

        # --- FILE READING ---
        read_indicators = ["read", "open", "show contents", "what's in", "contents of", "view"]
        if any(indicator in normalized for indicator in read_indicators):
            import re
            file_match = re.search(r"(?:read|open|view|contents?\s*of)\s*(?:the\s*)?(?:file\s*)?[\"']?(\S+\.\w+)[\"']?", normalized)
            if file_match:
                filepath = file_match.group(1).strip("\"'")
                return ExecutionPlan(
                    reasoning=f"Read contents of file '{filepath}'.",
                    steps=[ToolCall(
                        tool="filesystem.read",
                        args={"path": filepath, "max_size": 50000},
                        description=f"Read file {filepath}"
                    )],
                    requires_confirmation=False
                )

        # --- FILE DELETION ---
        delete_indicators = ["delete", "remove", "trash", "erase"]
        if any(indicator in normalized for indicator in delete_indicators):
            import re
            file_match = re.search(r"(?:delete|remove|trash|erase)\s*(?:the\s*)?(?:file\s*)?[\"']?(\S+)[\"']?", normalized)
            if file_match:
                filepath = file_match.group(1).strip("\"'")
                return ExecutionPlan(
                    reasoning=f"Delete file '{filepath}' (requires confirmation).",
                    steps=[ToolCall(
                        tool="filesystem.safe_delete",
                        args={"path": filepath, "confirm": False},
                        description=f"Delete {filepath}"
                    )],
                    requires_confirmation=True,
                    confirmation_message=f"Are you sure you want to delete '{filepath}'?",
                    risk_level="high"
                )

        # --- FILE RENAME ---
        rename_indicators = ["rename", "change name"]
        if any(indicator in normalized for indicator in rename_indicators):
            import re
            rename_match = re.search(r"(?:rename|change\s*name\s*of)\s*[\"']?(\S+)[\"']?\s*(?:to|as)\s*[\"']?(\S+)[\"']?", normalized)
            if rename_match:
                old_name = rename_match.group(1).strip("\"'")
                new_name = rename_match.group(2).strip("\"'")
                return ExecutionPlan(
                    reasoning=f"Rename '{old_name}' to '{new_name}'.",
                    steps=[ToolCall(
                        tool="filesystem.rename",
                        args={"path": old_name, "new_name": new_name},
                        description=f"Rename {old_name} to {new_name}"
                    )],
                    requires_confirmation=True,
                    confirmation_message=f"Rename '{old_name}' to '{new_name}'?",
                    risk_level="medium"
                )

        # --- FILE MOVE ---
        move_indicators = ["move", "mv"]
        if any(indicator in normalized for indicator in move_indicators):
            import re
            move_match = re.search(r"(?:move|mv)\s*[\"']?(\S+)[\"']?\s*(?:to|into)\s*[\"']?(\S+)[\"']?", normalized)
            if move_match:
                source = move_match.group(1).strip("\"'")
                destination = move_match.group(2).strip("\"'")
                return ExecutionPlan(
                    reasoning=f"Move '{source}' to '{destination}'.",
                    steps=[ToolCall(
                        tool="filesystem.move",
                        args={"source": source, "destination": destination},
                        description=f"Move {source} to {destination}"
                    )],
                    requires_confirmation=True,
                    confirmation_message=f"Move '{source}' to '{destination}'?",
                    risk_level="medium"
                )

        # --- FILE COPY ---
        copy_indicators = ["copy", "duplicate", "cp"]
        if any(indicator in normalized for indicator in copy_indicators):
            import re
            copy_match = re.search(r"(?:copy|duplicate|cp)\s*[\"']?(\S+)[\"']?\s*(?:to|as)\s*[\"']?(\S+)[\"']?", normalized)
            if copy_match:
                source = copy_match.group(1).strip("\"'")
                destination = copy_match.group(2).strip("\"'")
                return ExecutionPlan(
                    reasoning=f"Copy '{source}' to '{destination}'.",
                    steps=[ToolCall(
                        tool="filesystem.copy",
                        args={"source": source, "destination": destination},
                        description=f"Copy {source} to {destination}"
                    )],
                    requires_confirmation=False
                )

        # --- FILE INFO ---
        info_indicators = ["info", "details", "properties", "size of", "when was"]
        if any(indicator in normalized for indicator in info_indicators):
            import re
            file_match = re.search(r"(?:info|details|properties|size)\s*(?:of|about)?\s*[\"']?(\S+)[\"']?", normalized)
            if file_match:
                filepath = file_match.group(1).strip("\"'")
                return ExecutionPlan(
                    reasoning=f"Get information about '{filepath}'.",
                    steps=[ToolCall(
                        tool="filesystem.info",
                        args={"path": filepath},
                        description=f"Get info for {filepath}"
                    )],
                    requires_confirmation=False
                )

        # --- ORGANIZE FOLDER ---
        if "organize" in normalized:
            import re
            folder_match = re.search(r"organize\s*(?:my\s*)?[\"']?(\S+)[\"']?", normalized)
            folder_path = folder_match.group(1).strip("\"'") if folder_match else "~/Downloads"

            # Resolve alias
            for alias, path in folder_aliases.items():
                if alias in folder_path.lower():
                    folder_path = path
                    break

            return ExecutionPlan(
                reasoning=f"Organize files in '{folder_path}' by type.",
                steps=[ToolCall(
                    tool="filesystem.organize",
                    args={"path": folder_path, "dry_run": True},
                    description=f"Organize {folder_path} (preview)"
                )],
                requires_confirmation=True,
                confirmation_message=f"Organize files in '{folder_path}'?",
                risk_level="medium"
            )

        # =====================================================
        # END FILESYSTEM CRUD ROUTING - FALL THROUGH TO LLM
        # =====================================================

        # Log context size
        context_size = self._get_context_size()
        logger.info(f"Current context size: ~{context_size} tokens")

        # Get tool schemas
        # tools = self.tool_registry.get_all_schemas()
        # tools_json = json.dumps(tools, indent=2)
        
        # OPTIMIZATION: Only send tool names to save tokens for BitNet CPU
        tools_list = [t["name"] for t in self.tool_registry.list_tools()]
        tools_json = ", ".join(tools_list)

        # Format context
        context_dict = context if isinstance(context, dict) else asdict(context)
        context_json = json.dumps(context_dict, indent=2)

        # Build system prompt
        system_prompt = SYSTEM_PROMPT.format(
            tools_json=tools_json,
            context_json=context_json
        )

        # Build planning prompt
        planning_prompt = PLANNING_PROMPT.format(user_message=user_message)

        # Use conversation history for context
        conversation_context = self._build_conversation_context()
        messages = conversation_context + [
            {"role": "user", "content": planning_prompt}
        ]

        try:
            response = await self.llm.complete_chat(
                messages=messages,
                system_prompt=system_prompt,
                temperature=0.1,
                max_tokens=2048
            )

            # Parse response
            content = response.content.strip()

            # Extract JSON from response
            plan_data = self._extract_json(content)

            if not plan_data:
                # Fallback: create a simple response plan
                return ExecutionPlan(
                    reasoning="Unable to parse plan, providing direct response",
                    steps=[],
                    requires_confirmation=False
                )

            plan = ExecutionPlan.from_dict(plan_data)

            # Validate and adjust plan
            plan = self._validate_plan(plan)

            return plan

        except Exception as e:
            logger.exception(f"Error creating plan: {e}")
            return ExecutionPlan(
                reasoning=f"Error creating plan: {e}",
                steps=[],
                requires_confirmation=False
            )

    def _extract_json(self, content: str) -> Optional[dict]:
        """Extract JSON from LLM response."""
        # Try direct parse
        try:
            return json.loads(content)
        except json.JSONDecodeError:
            pass

        # Try to find JSON in content
        import re
        json_match = re.search(r'\{[\s\S]*\}', content)
        if json_match:
            try:
                return json.loads(json_match.group())
            except json.JSONDecodeError:
                pass

        # Try removing markdown code blocks
        if "```" in content:
            lines = content.split("\n")
            json_lines = []
            in_block = False
            for line in lines:
                if line.strip().startswith("```"):
                    in_block = not in_block
                elif in_block:
                    json_lines.append(line)

            if json_lines:
                try:
                    return json.loads("\n".join(json_lines))
                except json.JSONDecodeError:
                    pass

        return None

    def _validate_plan(self, plan: ExecutionPlan) -> ExecutionPlan:
        """Validate and adjust execution plan."""
        valid_steps = []

        for step in plan.steps:
            # Check if tool exists
            if self.tool_registry.has_tool(step.tool):
                # Validate parameters against schema
                schema = self.tool_registry.get_schema(step.tool)
                if schema:
                    # Basic validation - could be more thorough
                    valid_steps.append(step)
                else:
                    valid_steps.append(step)
            else:
                logger.warning(f"Unknown tool in plan: {step.tool}")

        plan.steps = valid_steps

        # Check if confirmation is needed
        destructive_tools = [
            "filesystem.delete", "filesystem.move", "filesystem.write",
            "system.shutdown", "system.restart", "system.update"
        ]

        for step in plan.steps:
            if step.tool in destructive_tools:
                plan.requires_confirmation = True
                if not plan.confirmation_message:
                    plan.confirmation_message = f"This action will use {step.tool}. Continue?"
                break

        return plan

    async def synthesize_response(
        self,
        user_message: str,
        plan: ExecutionPlan,
        results: list[ToolResult]
    ) -> str:
        """
        Synthesize a user-friendly response from execution results.

        Args:
            user_message: Original user request
            plan: The execution plan that was followed
            results: Results from each tool execution

        Returns:
            Natural language response for the user
        """
        # Check if this was a "garbled message" plan
        if plan.reasoning == "Message unclear - ask user to rephrase.":
            response = "I'm not quite sure what you meant. Could you please rephrase your question?"
            self._add_to_history("assistant", response)
            return response

        # If no tools were executed, generate direct response from LLM
        if not results:
            logger.info(f"[PLANNER] No tools executed, generating direct LLM response for: '{user_message[:50]}...'")

            # Use conversation history for better context
            conversation_context = self._build_conversation_context()

            # Build a simple, focused system prompt
            system_content = (
                "You are Ember-VLM, a helpful local AI assistant running on the user's computer. "
                "Answer questions directly and concisely. "
                "For general knowledge questions, provide accurate, brief answers. "
                "If asked about your identity, say you are 'Ember-VLM'. "
                "Keep responses under 100 words unless more detail is specifically requested."
            )

            # Build messages - keep it simple to avoid timeouts
            messages = [
                {"role": "system", "content": system_content}
            ]

            # Add limited history (last 4 messages max to prevent timeouts)
            recent_history = conversation_context[-4:] if len(conversation_context) > 4 else conversation_context
            messages.extend(recent_history)

            # Add current user message
            messages.append({"role": "user", "content": user_message})

            try:
                logger.info(f"[PLANNER] Sending to LLM with {len(messages)} messages")
                response = await self.llm.complete_chat(
                    messages=messages,
                    temperature=0.7,  # Slightly higher for more natural responses
                    max_tokens=200   # Keep responses short to prevent timeouts
                )

                if response and response.content:
                    assistant_response = response.content.strip()
                    logger.info(f"[PLANNER] Got LLM response: '{assistant_response[:100]}...'")
                else:
                    assistant_response = "I'm here to help! What would you like to know or do?"
                    logger.warning("[PLANNER] LLM returned empty response")

                # Add to history
                self._add_to_history("assistant", assistant_response)

                return assistant_response

            except Exception as e:
                logger.exception(f"[PLANNER] Error getting direct LLM response: {e}")
                # Provide a helpful fallback
                fallback = "I'm Ember-VLM, your local AI assistant. I can help you with files, documents, system info, and answer questions. What would you like to do?"
                self._add_to_history("assistant", fallback)
                return fallback

        # We have tool results - format them nicely
        logger.info(f"[PLANNER] Synthesizing response for {len(results)} tool results")

        # First, try to format results directly without LLM (faster)
        direct_response = self._format_results_fallback(results)

        # If the direct formatting looks good, use it
        if direct_response and len(direct_response) > 20:
            self._add_to_history("assistant", direct_response)
            return direct_response

        # Otherwise, try LLM synthesis with a short timeout
        results_json = json.dumps([r.to_dict() for r in results], indent=2)

        synthesis_prompt = SYNTHESIS_PROMPT.format(
            user_message=user_message,
            plan_json=json.dumps(plan.to_dict(), indent=2),
            results_json=results_json
        )

        messages = [{"role": "user", "content": synthesis_prompt}]

        try:
            response = await self.llm.complete_chat(
                messages=messages,
                temperature=0.3,
                max_tokens=200  # Keep it short
            )
            content = response.content.strip() if response and response.content else ""

            # If LLM didn't provide a response, use direct formatting
            if not content:
                content = direct_response if direct_response else "Task completed successfully."

            # Add to history
            self._add_to_history("assistant", content)

            return content

        except Exception as e:
            logger.exception(f"[PLANNER] Error synthesizing response: {e}")

            # Use the direct formatting as fallback
            fallback = direct_response if direct_response else "Task completed."
            self._add_to_history("assistant", fallback)
            return fallback

    def _format_results_fallback(self, results: list[ToolResult]) -> str:
        """Format results when LLM synthesis fails."""
        if not results:
            return "✓ Task completed."

        # For single result, try to extract useful info
        if len(results) == 1:
            result = results[0]
            if result.success and isinstance(result.result, dict):
                data = result.result

                # Handle filesystem.list results
                if "items" in data and "path" in data:
                    items = data["items"]
                    path = data["path"]
                    count = len(items)
                    total = data.get("total_count", count)
                    truncated = data.get("truncated", False)

                    if count == 0:
                        return f"No files found in {path}"

                    # Format file list
                    lines = [f"Found {count} items in {path}:"]
                    for i, item in enumerate(items[:20], 1):
                        name = item.get("name", "unknown")
                        is_dir = item.get("is_dir", False)
                        size = item.get("size", 0)
                        prefix = "[DIR]" if is_dir else "[FILE]"

                        if is_dir:
                            lines.append(f"{i}. {prefix} {name}/")
                        else:
                            size_str = self._format_size(size)
                            lines.append(f"{i}. {prefix} {name} ({size_str})")

                    if truncated and total > count:
                        lines.append(f"Showing {count} of {total} items. Reply 'show more' to continue.")

                    return "\n".join(lines)

                # Handle system.getcwd results
                elif "cwd" in data or "display" in data:
                    return f"Current directory: {data.get('display', data.get('cwd', 'unknown'))}"

            elif not result.success:
                return f"Error: {result.error}"

        # Multiple results - just show summary
        success_count = sum(1 for r in results if r.success)
        return f"Completed {success_count}/{len(results)} operations."

    def _format_size(self, size: int) -> str:
        """Format file size for display."""
        if size < 1024:
            return f"{size}B"
        elif size < 1024 * 1024:
            return f"{size / 1024:.1f}KB"
        elif size < 1024 * 1024 * 1024:
            return f"{size / (1024 * 1024):.1f}MB"
        else:
            return f"{size / (1024 * 1024 * 1024):.1f}GB"

    async def refine_plan(
        self,
        plan: ExecutionPlan,
        error: str,
        context: Any
    ) -> ExecutionPlan:
        """
        Refine a plan based on execution errors.

        Args:
            plan: The original plan
            error: Error that occurred
            context: Current system context

        Returns:
            Refined execution plan
        """
        refinement_prompt = f"""The following plan encountered an error:

Plan: {json.dumps(plan.to_dict(), indent=2)}

Error: {error}

Please provide a refined plan that addresses this error. Respond with the same JSON format."""

        messages = [{"role": "user", "content": refinement_prompt}]

        try:
            response = await self.llm.complete_chat(
                messages=messages,
                temperature=0.1,
                max_tokens=2048
            )

            plan_data = self._extract_json(response.content)
            if plan_data:
                return ExecutionPlan.from_dict(plan_data)

        except Exception as e:
            logger.exception(f"Error refining plan: {e}")

        return plan

