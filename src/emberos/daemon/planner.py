"""
Agent Planner for EmberOS.

Creates execution plans based on user commands and available tools,
then synthesizes responses from execution results.
"""

from __future__ import annotations

import json
import logging
from typing import Any, Optional
from dataclasses import dataclass, field, asdict
from datetime import datetime

from emberos.daemon.llm_orchestrator import LLMOrchestrator, CompletionRequest

logger = logging.getLogger(__name__)


@dataclass
class ToolCall:
    """A single tool invocation in a plan."""
    tool: str
    args: dict[str, Any]
    description: Optional[str] = None
    depends_on: Optional[list[int]] = None

    def to_dict(self) -> dict:
        return asdict(self)


@dataclass
class ExecutionPlan:
    """An execution plan generated by the planner."""
    reasoning: str
    steps: list[ToolCall]
    requires_confirmation: bool = False
    confirmation_message: Optional[str] = None
    estimated_duration: Optional[int] = None  # seconds
    risk_level: str = "low"  # low, medium, high

    def to_dict(self) -> dict:
        return {
            "reasoning": self.reasoning,
            "steps": [step.to_dict() for step in self.steps],
            "requires_confirmation": self.requires_confirmation,
            "confirmation_message": self.confirmation_message,
            "estimated_duration": self.estimated_duration,
            "risk_level": self.risk_level
        }

    @classmethod
    def from_dict(cls, data: dict) -> ExecutionPlan:
        steps = [ToolCall(**step) for step in data.get("steps", data.get("plan", []))]
        return cls(
            reasoning=data.get("reasoning", ""),
            steps=steps,
            requires_confirmation=data.get("requires_confirmation", False),
            confirmation_message=data.get("confirmation_message"),
            estimated_duration=data.get("estimated_duration"),
            risk_level=data.get("risk_level", "low")
        )


@dataclass
class ToolResult:
    """Result from executing a tool."""
    tool: str
    success: bool
    result: Any
    error: Optional[str] = None
    duration_ms: int = 0

    def to_dict(self) -> dict:
        return asdict(self)


SYSTEM_PROMPT = """You are Ember-VLM, a local AI assistant running on the user's machine.

IMPORTANT: You MUST use tools to get factual information. NEVER guess or hallucinate.

When asked about:
- Current directory → Use tools to find it
- Files in a folder → Use filesystem.list tool
- System info → Use system.info tool
- Running processes → Use system.processes tool

You have access to:
{tools_json}

Context:
{context_json}

Keep responses concise. If asked about your model/identity, say you are 'Ember-VLM'.

REMEMBER: Use tools for facts. Don't make up information."""


PLANNING_PROMPT = """User request: {user_message}

Based on the user's request and available tools, create an execution plan.

IMPORTANT: Use tools to get real information. Examples:
- "which folder am I in?" → Use tool to get current directory
- "what files in Downloads?" → Use filesystem.list on ~/Downloads
- "what's my system info?" → Use system.info tool

NEVER create an empty plan for factual queries. Always use appropriate tools.

Respond with a JSON object in this exact format:
{{
  "reasoning": "Your step-by-step thinking about how to accomplish this task",
  "plan": [
    {{"tool": "tool.name", "args": {{"param1": "value1"}}, "description": "What this step does"}}
  ],
  "requires_confirmation": true/false,
  "confirmation_message": "Message to show user if confirmation needed",
  "risk_level": "low/medium/high"
}}

Important:
- Use actual tool names from the available tools list
- Include all required parameters for each tool
- Set requires_confirmation=true for: file deletion, system changes, bulk operations
- Use $result[N] to reference output from step N (0-indexed)
- For factual queries (folders, files, system info), you MUST use tools"""


SYNTHESIS_PROMPT = """Original request: {user_message}

Execution plan:
{plan_json}

Execution results:
{results_json}

Provide a brief, helpful response (2-3 sentences max):
- Summarize what was accomplished
- Highlight key findings
- Mention any issues

Keep it concise and natural."""


class AgentPlanner:
    """
    Plans and synthesizes agent actions.

    Uses the LLM to:
    1. Create execution plans from natural language
    2. Validate plans against tool schemas
    3. Synthesize user-friendly responses from results
    """

    def __init__(self, llm: LLMOrchestrator, tool_registry):
        self.llm = llm
        self.tool_registry = tool_registry
        # Conversation history for context (sliding window)
        self._conversation_history: list[dict] = []
        self._max_history_turns = 50  # Keep last 50 turns (25 user + 25 assistant) - much longer context
        # State tracking for multi-step operations
        self._pending_document_creation: Optional[dict] = None  # Stores {topic, format, file_ext}

    def _add_to_history(self, role: str, content: str) -> None:
        """Add a message to conversation history with sliding window."""
        self._conversation_history.append({
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat()
        })

        # Apply sliding window: keep only last N turns
        if len(self._conversation_history) > self._max_history_turns * 2:
            # Keep last N turns (each turn = user + assistant)
            self._conversation_history = self._conversation_history[-(self._max_history_turns * 2):]
            logger.info(f"Trimmed conversation history to last {self._max_history_turns} turns")

    def _get_context_size(self) -> int:
        """Estimate context size in tokens (rough approximation)."""
        total_chars = sum(len(msg["content"]) for msg in self._conversation_history)
        # Rough estimate: 1 token ≈ 4 characters
        return total_chars // 4

    def _build_conversation_context(self) -> list[dict]:
        """Build conversation context from history."""
        context_size = self._get_context_size()
        if context_size > 15000:  # Increased from 3000 to 15000 for longer conversations
            logger.warning(f"Context size is {context_size} tokens - this may cause slowdowns")

        return self._conversation_history.copy()

    def clear_history(self) -> None:
        """Clear conversation history (useful for starting fresh)."""
        logger.info("Clearing conversation history")
        self._conversation_history = []

    async def _understand_intent_with_llm(self, text: str) -> tuple[str, str, bool]:
        """
        Use BitNet LLM to understand user intent and correct typos/errors.

        Returns:
            Tuple of (corrected_text, intent_type, needs_tools)
            - corrected_text: Corrected/clarified version of user input
            - intent_type: 'conversation' or 'system_task'
            - needs_tools: True if requires filesystem/system tools
        """
        # Comprehensive intent understanding prompt with edge case handling
        intent_prompt = f"""User input: "{text}"

Task: Fix typos/errors and classify intent.

OUTPUT FORMAT (exactly):
CORRECTED: [fixed text]
TYPE: [conversation|system_task|unclear]
TOOLS: [yes|no]
CONFIDENCE: [high|medium|low]

CLASSIFICATION RULES:

1. SYSTEM_TASK (needs tools):
   - File/folder operations: list, create, delete, move, copy, rename, search, find
   - System queries: current directory, disk space, processes, system info
   - Location queries: "where are you", "which folder", "current location", "where am I"
   - Keywords: file, folder, directory, downloads, documents, desktop, create, delete, open, read, write, where (location context)
   - Examples: "show files", "create folder", "what's in downloads", "where are you", "current directory"

2. CONVERSATION (no tools):
   - General knowledge: "what is X", "explain Y", "how does Z work"
   - Identity (NOT location): "who are you", "what are you", "what model", "introduce yourself"
   - Math: "calculate", "what is 2+2"
   - Greetings: "hello", "hi", "thanks", "goodbye"
   - Opinion/advice: "should I", "what do you think"
   - Examples: "what is gravity", "who are you" (identity), "calculate 5*3", "hello"
   
   Note: "where are you" is system_task (location), not conversation (identity)

3. UNCLEAR:
   - Completely garbled (>70% nonsense)
   - Empty or meaningless
   - Conflicting intents
   - Need clarification

EDGE CASES:

A. AMBIGUOUS QUERIES:
   - "open budget" → If "budget" is likely a file: system_task + tools=yes
   - "what is my folder" → system_task (asking for current directory)
   - "tell me about python" → conversation (general knowledge)
   - "tell me about my python files" → system_task (needs file search)

B. TYPOS & MISSPELLINGS:
   - Fix ALL typos: "shwo" → "show", "downlods" → "downloads", "wher ar u" → "where are you"
   - Handle missing spaces: "showfiles" → "show files"
   - Handle extra spaces: "show  files" → "show files"
   - Handle common shortcuts: "pls" → "please", "u" → "you", "r" → "are"

C. MIXED INTENTS (PRIORITIZE SYSTEM TASKS):
   - "what files are in downloads and what is a circle" → system_task (prioritize actionable)
   - "hello, list files" → system_task (ignore greeting, focus on action)
   - "hi, where are you?" → system_task (asking for current directory, not identity)
   - "hey, show me files" → system_task (ignore greeting)
   - "can you create a folder and explain gravity" → system_task (prioritize action)
   - "thanks, what's in my folder" → system_task (ignore acknowledgment)
   
   Rule: If ANY part asks for system info or file operations, classify as system_task

D. CONTEXT-DEPENDENT:
   - "show me" → If previous context exists, use it. Otherwise: unclear
   - "more" → If continuation expected: system_task. Otherwise: unclear
   - "that one" → Needs context: unclear (but note if it's a follow-up)

E. IMPLICIT SYSTEM TASKS:
   - "my downloads" → Implies "show my downloads": system_task
   - "budget file" → Implies "find budget file": system_task
   - "current location" → Implies "where am I": system_task

F. NATURAL LANGUAGE VARIATIONS:
   - "got any files here?" → "do you have any files here": system_task
   - "wanna see my downloads" → "want to see my downloads": system_task
   - "lemme see that folder" → "let me see that folder": system_task

G. GIBBERISH/UNCLEAR:
   - "asdfghjkl" → unclear (keyboard mashing)
   - "........." → unclear (no content)
   - "" (empty) → unclear
   - "jfkdsl wqepr nvmz" → unclear (no recognizable words)

H. CONFIDENCE LEVELS:
   - HIGH: Clear intent, correct grammar, obvious classification
   - MEDIUM: Some ambiguity but likely correct
   - LOW: Very ambiguous, multiple interpretations, typos make it unclear

EXAMPLES:

Input: "where ar you?"
CORRECTED: where are you?
TYPE: conversation
TOOLS: no
CONFIDENCE: high

Input: "shwo files in downlods"
CORRECTED: show files in downloads
TYPE: system_task
TOOLS: yes
CONFIDENCE: high

Input: "wat is a circle"
CORRECTED: what is a circle
TYPE: conversation
TOOLS: no
CONFIDENCE: high

Input: "hi, where are you?"
CORRECTED: hi, where are you?
TYPE: system_task
TOOLS: yes
CONFIDENCE: high

Input: "hello, what folder am i in"
CORRECTED: hello, what folder am I in
TYPE: system_task
TOOLS: yes
CONFIDENCE: high

Input: "crete a floder"
CORRECTED: create a folder
TYPE: system_task
TOOLS: yes
CONFIDENCE: high

Input: "my downloads"
CORRECTED: show my downloads
TYPE: system_task
TOOLS: yes
CONFIDENCE: medium

Input: "open budget"
CORRECTED: open budget file
TYPE: system_task
TOOLS: yes
CONFIDENCE: medium

Input: "asdfghjkl"
CORRECTED: [unable to correct]
TYPE: unclear
TOOLS: no
CONFIDENCE: low

Input: "what is python and list my files"
CORRECTED: what is python and list my files
TYPE: system_task
TOOLS: yes
CONFIDENCE: medium

Now analyze: "{text}"
"""

        try:
            # Use BitNet with very short timeout
            response = await self.llm.complete_chat(
                messages=[{"role": "user", "content": intent_prompt}],
                temperature=0.1,
                max_tokens=100  # Keep it very short
            )

            if not response or not response.content:
                # Fallback to original
                return text, "conversation", False

            content = response.content.strip()

            # Parse the response
            corrected = text
            intent_type = "conversation"
            needs_tools = False
            confidence = "medium"

            for line in content.split('\n'):
                line = line.strip()
                if line.startswith('CORRECTED:'):
                    raw_corrected = line.replace('CORRECTED:', '').strip()
                    # Handle special cases
                    if raw_corrected and '[unable to correct]' not in raw_corrected.lower():
                        corrected = raw_corrected
                elif line.startswith('TYPE:'):
                    intent_type = line.replace('TYPE:', '').strip().lower()
                elif line.startswith('TOOLS:'):
                    needs_tools = line.replace('TOOLS:', '').strip().lower() == 'yes'
                elif line.startswith('CONFIDENCE:'):
                    confidence = line.replace('CONFIDENCE:', '').strip().lower()

            # Handle unclear cases
            if intent_type == "unclear":
                logger.warning(f"[PLANNER] Intent unclear for: '{text}'")
                # Return original text and mark as conversation with low confidence
                # The synthesize_response will handle this gracefully
                return text, "unclear", False

            # Handle low confidence - be more cautious
            if confidence == "low":
                logger.warning(f"[PLANNER] Low confidence intent: '{text}' -> '{corrected}'")
                # For low confidence, prefer conversation to avoid wrong actions
                if intent_type == "system_task" and not any(word in text.lower() for word in [
                    'file', 'folder', 'directory', 'create', 'delete', 'list', 'show'
                ]):
                    intent_type = "conversation"
                    needs_tools = False

            logger.info(f"[PLANNER] Intent: '{text}' -> '{corrected}' (type={intent_type}, tools={needs_tools}, confidence={confidence})")

            # Return results
            return corrected, intent_type, needs_tools

        except Exception as e:
            logger.warning(f"[PLANNER] Intent understanding failed: {e}, using original text")
            # Fallback: assume conversation if no clear system indicators
            needs_tools = any(word in text.lower() for word in [
                'file', 'folder', 'directory', 'create', 'delete', 'list', 'show',
                'download', 'document', 'desktop'
            ])
            return text, "system_task" if needs_tools else "conversation", needs_tools

    async def create_plan(
        self,
        user_message: str,
        context: Any
    ) -> ExecutionPlan:
        """
        Create an execution plan for a user request.

        Args:
            user_message: The user's natural language request
            context: Current system context

        Returns:
            ExecutionPlan with steps to execute
        """
        # Add user message to history
        self._add_to_history("user", user_message)

        # =====================================================
        # STEP -1: CHECK IF WE'RE WAITING FOR DOCUMENT CREATION INFO
        # =====================================================
        if self._pending_document_creation is not None:
            import re

            normalized = user_message.strip().lower()
            doc_info = self._pending_document_creation

            # Extract filename and location from user response
            # Patterns: "filename.txt in Desktop", "create it as name.txt in Documents", etc.
            location_pattern = r"(?:as\s+|named\s+)?([^\s]+\.\w+)\s+(?:in|at|to)\s+([^\s]+)"
            match = re.search(location_pattern, normalized)

            filename = None
            location = None

            if match:
                filename = match.group(1)
                location = match.group(2)
            else:
                # Try simpler patterns
                # Just filename mentioned
                filename_pattern = r"([^\s]+\.\w+)"
                filename_match = re.search(filename_pattern, normalized)
                if filename_match:
                    filename = filename_match.group(1)

                # Location keywords
                for loc_keyword in ["desktop", "downloads", "documents", "pictures", "videos", "music"]:
                    if loc_keyword in normalized:
                        location = loc_keyword
                        break

            # If we got filename info, proceed with document creation
            if not filename or not location:
                # Still missing required info, ask again
                return ExecutionPlan(
                    reasoning="Need filename and location to create the document.",
                    steps=[],
                    requires_confirmation=False,
                    confirmation_message="DOCUMENT_CREATION_PROMPT",
                    risk_level="low"
                )

            # If user provided a filename with an extension, honor it and update format
            if filename:
                ext = os.path.splitext(filename)[1].lower()
                if ext in ['.txt', '.md', '.docx', '.pdf']:
                    doc_info['file_ext'] = ext
                    # Update format name
                    format_map = {'.txt': 'txt', '.md': 'md', '.docx': 'docx', '.pdf': 'pdf'}
                    doc_info['format'] = format_map.get(ext, doc_info['format'])
                    logger.info(f"[PLANNER] User provided extension {ext}, updated format to {doc_info['format']}")

            # Use defaults if missing
            if not filename:
                safe_topic = re.sub(r'[^\w\s-]', '', doc_info['topic']).strip().replace(' ', '_')[:50]
                filename = f"{safe_topic}{doc_info['file_ext']}"

            if not location:
                location = "~"  # Home directory as default
            else:
                # Map common location names to paths
                location_map = {
                    "desktop": "~/Desktop",
                    "downloads": "~/Downloads",
                    "documents": "~/Documents",
                    "pictures": "~/Pictures",
                    "videos": "~/Videos",
                    "music": "~/Music",
                }
                location = location_map.get(location.lower(), location)

            # Ensure filename has correct extension
            if not filename.endswith(doc_info['file_ext']):
                filename = f"{filename}{doc_info['file_ext']}"

            # Build full path
            import os
            filepath = os.path.join(os.path.expanduser(location), filename)

            logger.info(f"[PLANNER] Document creation: topic='{doc_info['topic']}', file='{filepath}'")

            # Clear pending state
            pending = self._pending_document_creation
            self._pending_document_creation = None

            # Create plan to generate content and write file
            # We'll generate content in the planner and then write it
            return ExecutionPlan(
                reasoning=f"Generate document content about '{pending['topic']}' and save to {filepath}",
                steps=[],  # Will be handled specially in synthesis
                requires_confirmation=False,
                confirmation_message=f"GENERATE_DOCUMENT|{pending['topic']}|{filepath}|{pending['format']}|{pending['length']}"
            )

        # =====================================================
        # STEP 0: INTELLIGENT INTENT UNDERSTANDING
        # Use BitNet to understand intent and correct typos
        # =====================================================

        normalized = user_message.strip().lower()

        # Fast-path: detect content-creation requests before intent classification
        create_indicators = ["create", "make", "new", "generate", "write"]
        content_keywords = ["about", "explaining", "on the topic", "regarding", "describing"]
        has_content_request = any(keyword in normalized for keyword in content_keywords)
        force_content_flow = any(indicator in normalized for indicator in create_indicators) and has_content_request

        # Quick check: if message looks mostly correct, skip LLM intent check
        # This saves time for well-formed queries
        skip_intent_check = (
            force_content_flow or
            len(normalized.split()) <= 2 or  # Very short
            normalized.startswith(':') or     # Command
            not any(c.isalpha() for c in normalized)  # No letters
        )

        corrected_message = normalized
        intent_type = "unknown"
        needs_tools = False

        if force_content_flow:
            intent_type = "system_task"
            needs_tools = True
        elif not skip_intent_check:
            # Use LLM to understand intent and correct typos
            try:
                corrected_message, intent_type, needs_tools = await self._understand_intent_with_llm(normalized)

                # If corrected significantly, log it
                if corrected_message.lower() != normalized.lower():
                    logger.info(f"[PLANNER] Corrected: '{normalized}' -> '{corrected_message}'")
                    normalized = corrected_message.lower()

            except Exception as e:
                logger.warning(f"[PLANNER] Intent understanding failed: {e}, using heuristics")
                # Fallback to simple heuristics
                needs_tools = any(word in normalized for word in [
                    'file', 'folder', 'directory', 'create', 'delete', 'list', 'show',
                    'download', 'document', 'desktop', 'find', 'search', 'open'
                ])
                intent_type = "system_task" if needs_tools else "conversation"

        # =====================================================
        # STEP 1: ROUTE BASED ON INTENT
        # =====================================================

        # Handle unclear intent - ask user to clarify
        if intent_type == "unclear":
            logger.info("[PLANNER] Intent unclear, asking user to rephrase")
            return ExecutionPlan(
                reasoning="User input unclear - ask for clarification.",
                steps=[],
                requires_confirmation=False
            )

        # If intent is clearly conversational and needs no tools, return empty plan
        if intent_type == "conversation" and not needs_tools:
            return ExecutionPlan(
                reasoning="Conversational query - respond directly without tools.",
                steps=[],
                requires_confirmation=False
            )

        # =====================================================
        # STEP 2: FILESYSTEM CRUD RULE-BASED ROUTING
        # These require tools to interact with the system
        # =====================================================

        # --- IDENTITY QUESTIONS ---
        identity_phrases = [
            "what are you", "who are you", "what model", "which model",
            "what llm", "what ai", "your name", "tell me about yourself",
            "introduce yourself", "are you gpt", "are you chatgpt",
            "are you claude", "are you llama", "what can you do",
            "your capabilities", "help me"
        ]
        if any(phrase in normalized for phrase in identity_phrases):
            # Return empty plan - will trigger direct LLM response
            return ExecutionPlan(
                reasoning="Identity/capability question - respond directly without tools.",
                steps=[],
                requires_confirmation=False
            )

        # --- GENERAL KNOWLEDGE QUESTIONS ---
        # These don't need tools - they're just knowledge questions
        general_knowledge_indicators = [
            # Question words that typically indicate general knowledge
            "does a ", "is a ", "are there ", "what is a ", "what are ",
            "how does ", "how do ", "why is ", "why do ", "why are ",
            "can a ", "could a ", "would a ", "should a ",
            "explain ", "tell me about ", "describe ",
            "what's the difference", "compare ", "versus ",
            # Math and logic
            "calculate ", "compute ", "what is ", "how many ", "how much ",
            # Facts
            "who invented", "who created", "who discovered", "when was ",
            "where is ", "what year ", "how old is ",
            # Concepts
            "define ", "meaning of ", "what does ", "definition of "
        ]

        # Check if this is a general knowledge question (not about files/system)
        system_indicators = [
            "file", "folder", "directory", "download", "document", "desktop",
            "system", "process", "memory", "disk", "cpu", "computer",
            "create", "delete", "move", "copy", "rename", "open", "read",
            "my ", "this ", "here", "current"
        ]

        is_general_knowledge = any(indicator in normalized for indicator in general_knowledge_indicators)
        is_system_related = any(indicator in normalized for indicator in system_indicators)

        if is_general_knowledge and not is_system_related:
            # This is a general knowledge question - respond directly
            return ExecutionPlan(
                reasoning="General knowledge question - respond directly using LLM knowledge.",
                steps=[],
                requires_confirmation=False
            )

        # --- SIMPLE CONVERSATIONAL QUERIES ---
        simple_phrases = [
            "hello", "hi", "hey", "good morning", "good afternoon", "good evening",
            "thanks", "thank you", "bye", "goodbye", "okay", "ok", "yes", "no",
            "cool", "nice", "great", "awesome", "sure", "alright"
        ]
        if normalized.strip() in simple_phrases or len(normalized.split()) <= 2:
            # Very short or greeting - respond directly
            if not any(word in normalized for word in ["list", "show", "find", "create", "delete", "open"]):
                return ExecutionPlan(
                    reasoning="Simple greeting or acknowledgment - respond directly.",
                    steps=[],
                    requires_confirmation=False
                )

        # =====================================================
        # STEP 2: FILESYSTEM CRUD RULE-BASED ROUTING
        # These require tools to interact with the system
        # Note: We still keep these fast-path rules for common queries
        # to avoid unnecessary LLM calls
        # =====================================================

        # --- WORKING DIRECTORY ---
        if any(phrase in normalized for phrase in [
            "which folder am i in",
            "where am i",
            "current directory",
            "working directory",
            "which folder are you in",
            "where are you",
            "pwd",
            "cwd"
        ]):
            return ExecutionPlan(
                reasoning="Use system.getcwd to return the current working directory.",
                steps=[ToolCall(tool="system.getcwd", args={}, description="Get current working directory")],
                requires_confirmation=False
            )

        # --- WHAT FOLDERS CAN YOU SEE ---
        if any(phrase in normalized for phrase in [
            "which folders can you see",
            "what folders can you see",
            "what folders do you see",
            "show me folders",
            "list folders",
            "available folders",
            "what folders are there",
            "what directories",
            "list my folders"
        ]):
            return ExecutionPlan(
                reasoning="List folders in user's home directory.",
                steps=[ToolCall(
                    tool="filesystem.list_enhanced",
                    args={"path": "~", "page_size": 20},
                    description="List folders in home directory"
                )],
                requires_confirmation=False
            )

        # --- PAGINATION CONTINUATION ---
        if any(phrase in normalized for phrase in [
            "show more",
            "list more",
            "continue",
            "next page",
            "more items",
            "more files",
            "keep going",
            "yes, show more",
            "yes show more"
        ]) and "stop" not in normalized:
            # Get last pagination session from context if available
            return ExecutionPlan(
                reasoning="Continue listing from previous pagination state.",
                steps=[ToolCall(
                    tool="filesystem.list_enhanced",
                    args={"path": ".", "continue_pagination": True, "page_size": 10},
                    description="Show next page of directory listing"
                )],
                requires_confirmation=False
            )

        # --- STOP PAGINATION ---
        if any(phrase in normalized for phrase in [
            "stop",
            "enough",
            "that's all",
            "no more",
            "cancel",
            "don't show more"
        ]):
            return ExecutionPlan(
                reasoning="User requested to stop listing.",
                steps=[],
                requires_confirmation=False
            )

        # --- DIRECTORY LISTING (Enhanced matching) ---
        # Common patterns: "what files in X", "show X folder", "list X", "what's in X"
        list_patterns = [
            r"(?:what|which|show|list|display|see)\s*(?:files?|folders?|items?|contents?)?\s*(?:are\s*)?(?:in|inside|on|at)?\s*(?:my\s*)?(\w+)",
            r"(?:what's|whats)\s*(?:in|inside)\s*(?:my\s*)?(\w+)",
            r"(?:list|show|display)\s*(?:my\s*)?(\w+)\s*(?:folder|directory)?",
            r"(?:open|go to)\s*(?:my\s*)?(\w+)",
        ]

        folder_aliases = {
            "desktop": "~/Desktop",
            "downloads": "~/Downloads",
            "documents": "~/Documents",
            "pictures": "~/Pictures",
            "videos": "~/Videos",
            "music": "~/Music",
            "home": "~",
        }

        # Check for explicit folder names in query
        for folder_name, folder_path in folder_aliases.items():
            if folder_name in normalized and any(word in normalized for word in [
                "files", "file", "list", "what", "show", "folder", "in", "inside", "open"
            ]):
                return ExecutionPlan(
                    reasoning=f"List files in {folder_name} directory.",
                    steps=[ToolCall(
                        tool="filesystem.list_enhanced",
                        args={"path": folder_path, "page_size": 10},
                        description=f"List files in {folder_name}"
                    )],
                    requires_confirmation=False
                )

        # Generic "list here" or "what files here"
        if any(phrase in normalized for phrase in [
            "what files here",
            "what's here",
            "whats here",
            "list here",
            "files here",
            "show files",
            "list files"
        ]) and not any(folder in normalized for folder in folder_aliases.keys()):
            return ExecutionPlan(
                reasoning="List files in current directory.",
                steps=[ToolCall(
                    tool="filesystem.list_enhanced",
                    args={"path": ".", "page_size": 10},
                    description="List files in current directory"
                )],
                requires_confirmation=False
            )

        # --- FILE SEARCH ---
        search_indicators = ["find", "search", "locate", "where is", "look for"]
        if any(indicator in normalized for indicator in search_indicators):
            import re
            # Try to extract filename from query
            search_match = re.search(
                r"(?:find|search|locate|look\s*for|where\s*is)\s*(?:my\s*)?(?:a\s*)?(?:file\s*)?(?:called\s*|named\s*)?[\"']?(\S+)[\"']?",
                normalized
            )
            if search_match:
                query = search_match.group(1).strip("\"'")
                return ExecutionPlan(
                    reasoning=f"Search for file matching '{query}'.",
                    steps=[ToolCall(
                        tool="filesystem.find",
                        args={"query": query, "path": "~", "max_results": 20},
                        description=f"Find files matching '{query}'"
                    )],
                    requires_confirmation=False
                )

        # --- FILE CREATION WITH CONTENT ---
        create_indicators = ["create", "make", "new", "generate", "write"]

        # Check for content generation requests (e.g., "create a document about X")
        content_keywords = ["about", "explaining", "on the topic", "regarding", "describing"]
        has_content_request = any(keyword in normalized for keyword in content_keywords)

        if any(indicator in normalized for indicator in create_indicators) and has_content_request:
            import re

            logger.info(f"[PLANNER] Detected content creation request: '{normalized}'")

            # Extract the topic - use multiple strategies
            topic_patterns = [
                # "about X" where X can be anything until end of string or location keywords
                r"(?:about|regarding|describing)\s+(.+?)(?:\s+(?:called|named|in|to|at|$))",
                # "explaining X"
                r"explaining\s+(.+?)(?:\s+(?:called|named|in|to|at|$))",
                # "on the topic of X"
                r"(?:on|of)\s+(?:the\s+topic\s+of\s+)?(.+?)(?:\s+(?:called|named|in|to|at|$))",
            ]

            topic = None
            for pattern in topic_patterns:
                match = re.search(pattern, normalized, re.IGNORECASE)
                if match:
                    topic = match.group(1).strip()
                    logger.info(f"[PLANNER] Extracted topic using pattern '{pattern}': '{topic}'")
                    # Clean up common endings
                    topic = re.sub(r"\s+(file|document|txt|md|markdown|word|pdf)$", "", topic, flags=re.IGNORECASE)
                    break

            # Fallback: if no topic found but has "about", extract everything after "about"
            if not topic:
                fallback_match = re.search(r"(?:about|regarding|describing)\s+(.+)$", normalized, re.IGNORECASE)
                if fallback_match:
                    topic = fallback_match.group(1).strip()
                    # Remove file type keywords from topic
                    topic = re.sub(r"^(txt|md|markdown|pdf|docx|doc|word)\s+", "", topic, flags=re.IGNORECASE)
                    topic = re.sub(r"\s+(file|document|txt|md|markdown|word|pdf)$", "", topic, flags=re.IGNORECASE)
                    logger.info(f"[PLANNER] Fallback topic extraction: '{topic}'")

            if topic:
                # Determine file format - check explicit format keywords
                format_type = "txt"
                file_ext = ".txt"

                # Use word boundaries to avoid matching "doc" in "document"
                import re
                if re.search(r'\b(markdown|\.md)\b', normalized):
                    format_type = "md"
                    file_ext = ".md"
                elif re.search(r'\b(docx|\.docx|word)\b', normalized) and not re.search(r'\btxt\b', normalized):
                    format_type = "docx"
                    file_ext = ".docx"
                elif re.search(r'\bpdf\b', normalized):
                    format_type = "pdf"
                    file_ext = ".pdf"
                # If user explicitly says "txt", keep it as txt (default)

                logger.info(f"[PLANNER] Detected format: {format_type} (file_ext: {file_ext})")

                # Extract filename if specified
                name_match = re.search(r"(?:called|named|with\s*(?:the\s*)?name)\s*[\"']?([^\s\"']+)[\"']?", normalized)
                filename = None
                if name_match:
                    filename = name_match.group(1).strip("\"'")
                    # Ensure proper extension
                    if not filename.endswith(('.txt', '.md', '.docx', '.pdf')):
                        filename += file_ext

                # Determine length
                length = "medium"
                if "short" in normalized or "brief" in normalized:
                    length = "short"
                elif "long" in normalized or "detailed" in normalized or "comprehensive" in normalized:
                    length = "long"

                logger.info(f"[PLANNER] Content generation: topic='{topic}', format={format_type}, filename={filename}")

                # Store document creation info for next turn
                self._pending_document_creation = {
                    "topic": topic,
                    "format": format_type,
                    "file_ext": file_ext,
                    "length": length
                }

                # Create plan that will be handled by synthesize_response to ask for filename and location
                return ExecutionPlan(
                    reasoning=f"Need to ask user for filename and location before generating content about '{topic}'",
                    steps=[],  # Empty plan - will ask for filename in synthesize_response
                    requires_confirmation=False,  # Don't use confirmation flow
                    confirmation_message="DOCUMENT_CREATION_PROMPT",  # Special marker for synthesize
                    risk_level="low"
                )

        # Template-based file creation (original)
        # NOTE: This must come AFTER the content generation check above
        # so that "create a txt document about X" triggers content generation,
        # not template-based creation
        file_types = {
            "spreadsheet": ("filesystem.create_spreadsheet", {"path": "new_spreadsheet.csv", "template": "blank"}),
            "budget": ("filesystem.create_spreadsheet", {"path": "budget.csv", "template": "budget"}),
            "csv": ("filesystem.create_spreadsheet", {"path": "data.csv", "template": "blank"}),
            "python": ("filesystem.create_file", {"path": "script.py", "template": "python"}),
            "script": ("filesystem.create_file", {"path": "script.py", "template": "python"}),
            "javascript": ("filesystem.create_file", {"path": "script.js", "template": "javascript"}),
            "js": ("filesystem.create_file", {"path": "script.js", "template": "javascript"}),
            "html": ("filesystem.create_file", {"path": "page.html", "template": "html"}),
            "webpage": ("filesystem.create_file", {"path": "page.html", "template": "html"}),
            "markdown": ("filesystem.create_file", {"path": "document.md", "template": "markdown"}),
            "md": ("filesystem.create_file", {"path": "document.md", "template": "markdown"}),
            "readme": ("filesystem.create_file", {"path": "README.md", "template": "readme"}),
            "text": ("filesystem.create_file", {"path": "document.txt", "template": "blank"}),
            "txt": ("filesystem.create_file", {"path": "document.txt", "template": "blank"}),
            "file": ("filesystem.create_file", {"path": "new_file.txt", "template": "blank"}),
            "json": ("filesystem.create_file", {"path": "data.json", "template": "json"}),
            "yaml": ("filesystem.create_file", {"path": "config.yaml", "template": "yaml"}),
            "folder": ("filesystem.create_directory", {"path": "new_folder"}),
            "directory": ("filesystem.create_directory", {"path": "new_folder"}),
        }

        # Only use template-based creation if there's NO content request (about, explaining, etc.)
        if any(indicator in normalized for indicator in create_indicators) and not has_content_request:
            import re
            # Try to extract filename and file type
            name_match = re.search(r"(?:called|named|with\s*(?:the\s*)?name)\s*[\"']?(\S+)[\"']?", normalized)

            for file_type, (tool, default_args) in file_types.items():
                if file_type in normalized:
                    args = default_args.copy()

                    # Extract custom name if provided
                    if name_match:
                        custom_name = name_match.group(1).strip("\"'")
                        # Add appropriate extension if not present
                        if file_type in ["spreadsheet", "budget", "csv"]:
                            if not custom_name.endswith(".csv"):
                                custom_name += ".csv"
                        elif file_type in ["python", "script"]:
                            if not custom_name.endswith(".py"):
                                custom_name += ".py"
                        args["path"] = f"~/{custom_name}"

                    return ExecutionPlan(
                        reasoning=f"Create a new {file_type} file.",
                        steps=[ToolCall(tool=tool, args=args, description=f"Create {file_type} file")],
                        requires_confirmation=False
                    )

        # --- FILE READING ---
        read_indicators = ["read", "open", "show contents", "what's in", "contents of", "view"]
        if any(indicator in normalized for indicator in read_indicators):
            import re
            file_match = re.search(r"(?:read|open|view|contents?\s*of)\s*(?:the\s*)?(?:file\s*)?[\"']?(\S+\.\w+)[\"']?", normalized)
            if file_match:
                filepath = file_match.group(1).strip("\"'")
                return ExecutionPlan(
                    reasoning=f"Read contents of file '{filepath}'.",
                    steps=[ToolCall(
                        tool="filesystem.read",
                        args={"path": filepath, "max_size": 50000},
                        description=f"Read file {filepath}"
                    )],
                    requires_confirmation=False
                )

        # --- FILE DELETION ---
        delete_indicators = ["delete", "remove", "trash", "erase"]
        if any(indicator in normalized for indicator in delete_indicators):
            import re
            file_match = re.search(r"(?:delete|remove|trash|erase)\s*(?:the\s*)?(?:file\s*)?[\"']?(\S+)[\"']?", normalized)
            if file_match:
                filepath = file_match.group(1).strip("\"'")
                return ExecutionPlan(
                    reasoning=f"Delete file '{filepath}' (requires confirmation).",
                    steps=[ToolCall(
                        tool="filesystem.safe_delete",
                        args={"path": filepath, "confirm": False},
                        description=f"Delete {filepath}"
                    )],
                    requires_confirmation=True,
                    confirmation_message=f"Are you sure you want to delete '{filepath}'?",
                    risk_level="high"
                )

        # --- FILE RENAME ---
        rename_indicators = ["rename", "change name"]
        if any(indicator in normalized for indicator in rename_indicators):
            import re
            rename_match = re.search(r"(?:rename|change\s*name\s*of)\s*[\"']?(\S+)[\"']?\s*(?:to|as)\s*[\"']?(\S+)[\"']?", normalized)
            if rename_match:
                old_name = rename_match.group(1).strip("\"'")
                new_name = rename_match.group(2).strip("\"'")
                return ExecutionPlan(
                    reasoning=f"Rename '{old_name}' to '{new_name}'.",
                    steps=[ToolCall(
                        tool="filesystem.rename",
                        args={"path": old_name, "new_name": new_name},
                        description=f"Rename {old_name} to {new_name}"
                    )],
                    requires_confirmation=True,
                    confirmation_message=f"Rename '{old_name}' to '{new_name}'?",
                    risk_level="medium"
                )

        # --- FILE MOVE ---
        move_indicators = ["move", "mv"]
        if any(indicator in normalized for indicator in move_indicators):
            import re
            move_match = re.search(r"(?:move|mv)\s*[\"']?(\S+)[\"']?\s*(?:to|into)\s*[\"']?(\S+)[\"']?", normalized)
            if move_match:
                source = move_match.group(1).strip("\"'")
                destination = move_match.group(2).strip("\"'")
                return ExecutionPlan(
                    reasoning=f"Move '{source}' to '{destination}'.",
                    steps=[ToolCall(
                        tool="filesystem.move",
                        args={"source": source, "destination": destination},
                        description=f"Move {source} to {destination}"
                    )],
                    requires_confirmation=True,
                    confirmation_message=f"Move '{source}' to '{destination}'?",
                    risk_level="medium"
                )

        # --- FILE COPY ---
        copy_indicators = ["copy", "duplicate", "cp"]
        if any(indicator in normalized for indicator in copy_indicators):
            import re
            copy_match = re.search(r"(?:copy|duplicate|cp)\s*[\"']?(\S+)[\"']?\s*(?:to|as)\s*[\"']?(\S+)[\"']?", normalized)
            if copy_match:
                source = copy_match.group(1).strip("\"'")
                destination = copy_match.group(2).strip("\"'")
                return ExecutionPlan(
                    reasoning=f"Copy '{source}' to '{destination}'.",
                    steps=[ToolCall(
                        tool="filesystem.copy",
                        args={"source": source, "destination": destination},
                        description=f"Copy {source} to {destination}"
                    )],
                    requires_confirmation=False
                )

        # --- FILE INFO ---
        info_indicators = ["info", "details", "properties", "size of", "when was"]
        if any(indicator in normalized for indicator in info_indicators):
            import re
            file_match = re.search(r"(?:info|details|properties|size)\s*(?:of|about)?\s*[\"']?(\S+)[\"']?", normalized)
            if file_match:
                filepath = file_match.group(1).strip("\"'")
                return ExecutionPlan(
                    reasoning=f"Get information about '{filepath}'.",
                    steps=[ToolCall(
                        tool="filesystem.info",
                        args={"path": filepath},
                        description=f"Get info for {filepath}"
                    )],
                    requires_confirmation=False
                )

        # --- ORGANIZE FOLDER ---
        if "organize" in normalized:
            import re
            folder_match = re.search(r"organize\s*(?:my\s*)?[\"']?(\S+)[\"']?", normalized)
            folder_path = folder_match.group(1).strip("\"'") if folder_match else "~/Downloads"

            # Resolve alias
            for alias, path in folder_aliases.items():
                if alias in folder_path.lower():
                    folder_path = path
                    break

            return ExecutionPlan(
                reasoning=f"Organize files in '{folder_path}' by type.",
                steps=[ToolCall(
                    tool="filesystem.organize",
                    args={"path": folder_path, "dry_run": True},
                    description=f"Organize {folder_path} (preview)"
                )],
                requires_confirmation=True,
                confirmation_message=f"Organize files in '{folder_path}'?",
                risk_level="medium"
            )

        # =====================================================
        # END FILESYSTEM CRUD ROUTING - FALL THROUGH TO LLM
        # =====================================================

        # Log context size
        context_size = self._get_context_size()
        logger.info(f"Current context size: ~{context_size} tokens")

        # Get tool schemas
        # tools = self.tool_registry.get_all_schemas()
        # tools_json = json.dumps(tools, indent=2)
        
        # OPTIMIZATION: Only send tool names to save tokens for BitNet CPU
        tools_list = [t["name"] for t in self.tool_registry.list_tools()]
        tools_json = ", ".join(tools_list)

        # Format context
        context_dict = context if isinstance(context, dict) else asdict(context)
        context_json = json.dumps(context_dict, indent=2)

        # Build system prompt
        system_prompt = SYSTEM_PROMPT.format(
            tools_json=tools_json,
            context_json=context_json
        )

        # Build planning prompt
        planning_prompt = PLANNING_PROMPT.format(user_message=user_message)

        # Use conversation history for context
        conversation_context = self._build_conversation_context()
        messages = conversation_context + [
            {"role": "user", "content": planning_prompt}
        ]

        try:
            response = await self.llm.complete_chat(
                messages=messages,
                system_prompt=system_prompt,
                temperature=0.1,
                max_tokens=2048
            )

            # Parse response
            content = response.content.strip()

            # Extract JSON from response
            plan_data = self._extract_json(content)

            if not plan_data:
                # Fallback: create a simple response plan
                return ExecutionPlan(
                    reasoning="Unable to parse plan, providing direct response",
                    steps=[],
                    requires_confirmation=False
                )

            plan = ExecutionPlan.from_dict(plan_data)

            # Validate and adjust plan
            plan = self._validate_plan(plan)

            return plan

        except Exception as e:
            logger.exception(f"Error creating plan: {e}")
            return ExecutionPlan(
                reasoning=f"Error creating plan: {e}",
                steps=[],
                requires_confirmation=False
            )

    def _extract_json(self, content: str) -> Optional[dict]:
        """Extract JSON from LLM response."""
        # Try direct parse
        try:
            return json.loads(content)
        except json.JSONDecodeError:
            pass

        # Try to find JSON in content
        import re
        json_match = re.search(r'\{[\s\S]*\}', content)
        if json_match:
            try:
                return json.loads(json_match.group())
            except json.JSONDecodeError:
                pass

        # Try removing markdown code blocks
        if "```" in content:
            lines = content.split("\n")
            json_lines = []
            in_block = False
            for line in lines:
                if line.strip().startswith("```"):
                    in_block = not in_block
                elif in_block:
                    json_lines.append(line)

            if json_lines:
                try:
                    return json.loads("\n".join(json_lines))
                except json.JSONDecodeError:
                    pass

        return None

    def _validate_plan(self, plan: ExecutionPlan) -> ExecutionPlan:
        """Validate and adjust execution plan."""
        valid_steps = []

        for step in plan.steps:
            # Check if tool exists
            if self.tool_registry.has_tool(step.tool):
                # Validate parameters against schema
                schema = self.tool_registry.get_schema(step.tool)
                if schema:
                    # Basic validation - could be more thorough
                    valid_steps.append(step)
                else:
                    valid_steps.append(step)
            else:
                logger.warning(f"Unknown tool in plan: {step.tool}")

        plan.steps = valid_steps

        # Check if confirmation is needed
        destructive_tools = [
            "filesystem.delete", "filesystem.move", "filesystem.write",
            "system.shutdown", "system.restart", "system.update"
        ]

        for step in plan.steps:
            if step.tool in destructive_tools:
                plan.requires_confirmation = True
                if not plan.confirmation_message:
                    plan.confirmation_message = f"This action will use {step.tool}. Continue?"
                break

        return plan

    async def synthesize_response(
        self,
        user_message: str,
        plan: ExecutionPlan,
        results: list[ToolResult]
    ) -> str:
        """
        Synthesize a user-friendly response from execution results.

        Args:
            user_message: Original user request
            plan: The execution plan that was followed
            results: Results from each tool execution

        Returns:
            Natural language response for the user
        """
        # Handle document generation - user has provided filename and location
        if plan.confirmation_message and plan.confirmation_message.startswith("GENERATE_DOCUMENT|"):
            parts = plan.confirmation_message.split("|")
            if len(parts) == 5:
                _, topic, filepath, format_type, length = parts

                try:
                    # Generate content using LLM
                    logger.info(f"[PLANNER] Generating {length} content about '{topic}'")

                    # Determine word count based on length
                    word_count = 150  # medium
                    if length == "short":
                        word_count = 75
                    elif length == "long":
                        word_count = 300

                    generation_prompt = f"Write a {length} {format_type} document (approximately {word_count} words) about: {topic}\n\nProvide clear, informative content. Do not include any meta-commentary about the task."

                    response = await self.llm.complete_chat(
                        messages=[{"role": "user", "content": generation_prompt}],
                        temperature=0.7,
                        max_tokens=word_count * 2  # Rough token estimate
                    )

                    if not response or not response.content:
                        self._add_to_history("assistant", "Sorry, I couldn't generate the content. Please try again.")
                        return "Sorry, I couldn't generate the content. Please try again."

                    content = response.content.strip()

                    # Now write the file using documents.create tool
                    import os
                    filepath_expanded = os.path.expanduser(filepath)

                    # Ensure directory exists
                    os.makedirs(os.path.dirname(filepath_expanded), exist_ok=True)

                    # For now, just write to txt/md files directly
                    # TODO: Use documents.create tool for proper formatting
                    extension = os.path.splitext(filepath_expanded)[1].lower()

                    if extension in ['.txt', '.md']:
                        with open(filepath_expanded, 'w', encoding='utf-8') as f:
                            if extension == '.md':
                                f.write(f"# {topic.title()}\n\n")
                            f.write(content)

                        response_msg = f"Created {format_type} document: {filepath}\n\nContent preview:\n{content[:200]}..."
                    else:
                        # For docx and pdf, we need proper tool support
                        response_msg = f"Sorry, creating {format_type} files is not yet fully supported. I can create TXT and Markdown files. Would you like me to create a .txt or .md file instead?"

                    self._add_to_history("assistant", response_msg)
                    return response_msg

                except Exception as e:
                    logger.exception(f"[PLANNER] Error generating document: {e}")
                    error_msg = f"Sorry, I encountered an error creating the document: {str(e)}"
                    self._add_to_history("assistant", error_msg)
                    return error_msg

        # Handle document creation prompt - need to ask for filename and location
        if plan.confirmation_message == "DOCUMENT_CREATION_PROMPT":
            import re

            doc_info = self._pending_document_creation or {}

            if doc_info:
                topic = doc_info.get("topic", "the requested content")
                format_type = doc_info.get("format", "TXT")
                file_ext = doc_info.get("file_ext", ".txt")
                length = doc_info.get("length", "medium")
            else:
                # Extract topic and format from the original message
                normalized = user_message.strip().lower()

                topic_patterns = [
                    r"(?:about|explaining|regarding|describing)\s+(.+?)(?:\s+(?:called|named|in|$))",
                    r"(?:on|of)\s+(?:the\s+topic\s+of\s+)?(.+?)(?:\s+(?:called|named|in|$))",
                ]

                topic = "the requested content"
                for pattern in topic_patterns:
                    match = re.search(pattern, normalized, re.IGNORECASE)
                    if match:
                        topic = match.group(1).strip()
                        topic = re.sub(r"\s+(file|document|txt|md|markdown|word|pdf)$", "", topic, flags=re.IGNORECASE)
                        break

                # Determine format
                format_type = "TXT"
                file_ext = ".txt"
                if any(word in normalized for word in ["markdown", "md"]):
                    format_type = "Markdown"
                    file_ext = ".md"
                elif any(word in normalized for word in ["word", "docx", "doc"]):
                    format_type = "Word"
                    file_ext = ".docx"
                elif any(word in normalized for word in ["pdf"]):
                    format_type = "PDF"
                    file_ext = ".pdf"

                # Determine length
                length = "medium"
                if "short" in normalized or "brief" in normalized:
                    length = "short"
                elif "long" in normalized or "detailed" in normalized or "comprehensive" in normalized:
                    length = "long"

                # Store pending document creation info
                self._pending_document_creation = {
                    "topic": topic,
                    "format": format_type,
                    "file_ext": file_ext,
                    "length": length
                }

            # Generate default filename from topic
            safe_topic = re.sub(r'[^\w\s-]', '', topic).strip().replace(' ', '_')[:50]
            suggested_name = f"{safe_topic}{file_ext}"

            # Ask user for filename and location
            response = (
                f"I'll create a {format_type} document about '{topic}'.\n\n"
                f"Please provide:\n"
                f"1. Filename (suggested: {suggested_name})\n"
                f"2. Location (e.g., Desktop, Downloads, Documents, or full path)\n\n"
                f"Example: 'Create it as sunlight.txt in Desktop'\n"
                f"Or simply: 'sunlight.txt in Desktop'"
            )

            self._add_to_history("assistant", response)
            return response

        # Handle unclear intent - ask for clarification
        if plan.reasoning == "User input unclear - ask for clarification.":
            response = (
                "I'm not quite sure what you're asking. Could you please rephrase? "
                "For example:\n"
                "• To see files: 'show files in downloads'\n"
                "• To ask a question: 'what is gravity'\n"
                "• To get help: 'what can you do'"
            )
            self._add_to_history("assistant", response)
            return response

        # If no tools were executed, generate direct response from LLM
        if not results:
            logger.info(f"[PLANNER] No tools executed, generating direct LLM response for: '{user_message[:50]}...'")

            # Use conversation history for better context
            conversation_context = self._build_conversation_context()

            # Build a simple, focused system prompt
            system_content = (
                "You are Ember-VLM, a helpful local AI assistant running on the user's computer. "
                "Answer questions directly and concisely. "
                "For general knowledge questions, provide accurate, brief answers. "
                "If asked about your identity, say you are 'Ember-VLM'. "
                "Keep responses under 100 words unless more detail is specifically requested."
            )

            # Build messages - keep it simple to avoid timeouts
            messages = [
                {"role": "system", "content": system_content}
            ]

            # Add limited history (last 4 messages max to prevent timeouts)
            recent_history = conversation_context[-4:] if len(conversation_context) > 4 else conversation_context
            messages.extend(recent_history)

            # Add current user message
            messages.append({"role": "user", "content": user_message})

            try:
                logger.info(f"[PLANNER] Sending to LLM with {len(messages)} messages")
                response = await self.llm.complete_chat(
                    messages=messages,
                    temperature=0.7,  # Slightly higher for more natural responses
                    max_tokens=200   # Keep responses short to prevent timeouts
                )

                if response and response.content:
                    assistant_response = response.content.strip()
                    logger.info(f"[PLANNER] Got LLM response: '{assistant_response[:100]}...'")
                else:
                    assistant_response = "I'm here to help! What would you like to know or do?"
                    logger.warning("[PLANNER] LLM returned empty response")

                # Add to history
                self._add_to_history("assistant", assistant_response)

                return assistant_response

            except Exception as e:
                logger.exception(f"[PLANNER] Error getting direct LLM response: {e}")
                # Provide a helpful fallback
                fallback = "I'm Ember-VLM, your local AI assistant. I can help you with files, documents, system info, and answer questions. What would you like to do?"
                self._add_to_history("assistant", fallback)
                return fallback

        # We have tool results - format them nicely
        logger.info(f"[PLANNER] Synthesizing response for {len(results)} tool results")

        # First, try to format results directly without LLM (faster)
        direct_response = self._format_results_fallback(results)

        # If the direct formatting looks good, use it
        if direct_response and len(direct_response) > 20:
            self._add_to_history("assistant", direct_response)
            return direct_response

        # Otherwise, try LLM synthesis with a short timeout
        results_json = json.dumps([r.to_dict() for r in results], indent=2)

        synthesis_prompt = SYNTHESIS_PROMPT.format(
            user_message=user_message,
            plan_json=json.dumps(plan.to_dict(), indent=2),
            results_json=results_json
        )

        messages = [{"role": "user", "content": synthesis_prompt}]

        try:
            response = await self.llm.complete_chat(
                messages=messages,
                temperature=0.3,
                max_tokens=200  # Keep it short
            )
            content = response.content.strip() if response and response.content else ""

            # If LLM didn't provide a response, use direct formatting
            if not content:
                content = direct_response if direct_response else "Task completed successfully."

            # Add to history
            self._add_to_history("assistant", content)

            return content

        except Exception as e:
            logger.exception(f"[PLANNER] Error synthesizing response: {e}")

            # Use the direct formatting as fallback
            fallback = direct_response if direct_response else "Task completed."
            self._add_to_history("assistant", fallback)
            return fallback

    def _format_results_fallback(self, results: list[ToolResult]) -> str:
        """Format results when LLM synthesis fails."""
        if not results:
            return "✓ Task completed."

        # For single result, try to extract useful info
        if len(results) == 1:
            result = results[0]
            if result.success and isinstance(result.result, dict):
                data = result.result

                # Handle filesystem.list results
                if "items" in data and "path" in data:
                    items = data["items"]
                    path = data["path"]
                    count = len(items)
                    total = data.get("total_count", count)
                    truncated = data.get("truncated", False)

                    if count == 0:
                        return f"No files found in {path}"

                    # Format file list
                    lines = [f"Found {count} items in {path}:"]
                    for i, item in enumerate(items[:20], 1):
                        name = item.get("name", "unknown")
                        is_dir = item.get("is_dir", False)
                        size = item.get("size", 0)
                        prefix = "[DIR]" if is_dir else "[FILE]"

                        if is_dir:
                            lines.append(f"{i}. {prefix} {name}/")
                        else:
                            size_str = self._format_size(size)
                            lines.append(f"{i}. {prefix} {name} ({size_str})")

                    if truncated and total > count:
                        lines.append(f"Showing {count} of {total} items. Reply 'show more' to continue.")

                    return "\n".join(lines)

                # Handle system.getcwd results
                elif "cwd" in data or "display" in data:
                    return f"Current directory: {data.get('display', data.get('cwd', 'unknown'))}"

            elif not result.success:
                return f"Error: {result.error}"

        # Multiple results - just show summary
        success_count = sum(1 for r in results if r.success)
        return f"Completed {success_count}/{len(results)} operations."

    def _format_size(self, size: int) -> str:
        """Format file size for display."""
        if size < 1024:
            return f"{size}B"
        elif size < 1024 * 1024:
            return f"{size / 1024:.1f}KB"
        elif size < 1024 * 1024 * 1024:
            return f"{size / (1024 * 1024):.1f}MB"
        else:
            return f"{size / (1024 * 1024 * 1024):.1f}GB"

    async def refine_plan(
        self,
        plan: ExecutionPlan,
        error: str,
        context: Any
    ) -> ExecutionPlan:
        """
        Refine a plan based on execution errors.

        Args:
            plan: The original plan
            error: Error that occurred
            context: Current system context

        Returns:
            Refined execution plan
        """
        refinement_prompt = f"""The following plan encountered an error:

Plan: {json.dumps(plan.to_dict(), indent=2)}

Error: {error}

Please provide a refined plan that addresses this error. Respond with the same JSON format."""

        messages = [{"role": "user", "content": refinement_prompt}]

        try:
            response = await self.llm.complete_chat(
                messages=messages,
                temperature=0.1,
                max_tokens=2048
            )

            plan_data = self._extract_json(response.content)
            if plan_data:
                return ExecutionPlan.from_dict(plan_data)

        except Exception as e:
            logger.exception(f"Error refining plan: {e}")

        return plan

