"""
Agent Planner for EmberOS.

Creates execution plans based on user commands and available tools,
then synthesizes responses from execution results.
"""

from __future__ import annotations

import json
import logging
from typing import Any, Optional
from dataclasses import dataclass, field, asdict
from datetime import datetime

from emberos.daemon.llm_orchestrator import LLMOrchestrator, CompletionRequest

logger = logging.getLogger(__name__)


@dataclass
class ToolCall:
    """A single tool invocation in a plan."""
    tool: str
    args: dict[str, Any]
    description: Optional[str] = None
    depends_on: Optional[list[int]] = None

    def to_dict(self) -> dict:
        return asdict(self)


@dataclass
class ExecutionPlan:
    """An execution plan generated by the planner."""
    reasoning: str
    steps: list[ToolCall]
    requires_confirmation: bool = False
    confirmation_message: Optional[str] = None
    estimated_duration: Optional[int] = None  # seconds
    risk_level: str = "low"  # low, medium, high

    def to_dict(self) -> dict:
        return {
            "reasoning": self.reasoning,
            "steps": [step.to_dict() for step in self.steps],
            "requires_confirmation": self.requires_confirmation,
            "confirmation_message": self.confirmation_message,
            "estimated_duration": self.estimated_duration,
            "risk_level": self.risk_level
        }

    @classmethod
    def from_dict(cls, data: dict) -> ExecutionPlan:
        steps = [ToolCall(**step) for step in data.get("steps", data.get("plan", []))]
        return cls(
            reasoning=data.get("reasoning", ""),
            steps=steps,
            requires_confirmation=data.get("requires_confirmation", False),
            confirmation_message=data.get("confirmation_message"),
            estimated_duration=data.get("estimated_duration"),
            risk_level=data.get("risk_level", "low")
        )


@dataclass
class ToolResult:
    """Result from executing a tool."""
    tool: str
    success: bool
    result: Any
    error: Optional[str] = None
    duration_ms: int = 0

    def to_dict(self) -> dict:
        return asdict(self)


SYSTEM_PROMPT = """You are EmberOS.
You have access to:
{tools_json}

Context:
{context_json}
"""


PLANNING_PROMPT = """User request: {user_message}

Based on the user's request and available tools, create an execution plan.

Respond with a JSON object in this exact format:
{{
  "reasoning": "Your step-by-step thinking about how to accomplish this task",
  "plan": [
    {{"tool": "tool.name", "args": {{"param1": "value1"}}, "description": "What this step does"}}
  ],
  "requires_confirmation": true/false,
  "confirmation_message": "Message to show user if confirmation needed",
  "risk_level": "low/medium/high"
}}

Important:
- Use actual tool names from the available tools list
- Include all required parameters for each tool
- Set requires_confirmation=true for: file deletion, system changes, bulk operations
- Use $result[N] to reference output from step N (0-indexed)"""


SYNTHESIS_PROMPT = """Original request: {user_message}

Execution plan:
{plan_json}

Execution results:
{results_json}

Based on the execution results, provide a helpful response to the user.
- Summarize what was accomplished
- Highlight key findings or results
- Mention any issues encountered
- Suggest follow-up actions if relevant

Keep the response concise and natural."""


class AgentPlanner:
    """
    Plans and synthesizes agent actions.

    Uses the LLM to:
    1. Create execution plans from natural language
    2. Validate plans against tool schemas
    3. Synthesize user-friendly responses from results
    """

    def __init__(self, llm: LLMOrchestrator, tool_registry: Any):
        self.llm = llm
        self.tool_registry = tool_registry

    async def create_plan(
        self,
        user_message: str,
        context: Any
    ) -> ExecutionPlan:
        """
        Create an execution plan for a user request.

        Args:
            user_message: The user's natural language request
            context: Current system context

        Returns:
            ExecutionPlan with steps to execute
        """
        # Get tool schemas
        # tools = self.tool_registry.get_all_schemas()
        # tools_json = json.dumps(tools, indent=2)
        
        # OPTIMIZATION: Only send tool names to save tokens for BitNet CPU
        tools_list = [t["name"] for t in self.tool_registry.list_tools()]
        tools_json = ", ".join(tools_list)

        # Format context
        context_dict = context if isinstance(context, dict) else asdict(context)
        context_json = json.dumps(context_dict, indent=2)

        # Build system prompt
        system_prompt = SYSTEM_PROMPT.format(
            tools_json=tools_json,
            context_json=context_json
        )

        # Build planning prompt
        planning_prompt = PLANNING_PROMPT.format(user_message=user_message)

        # Generate plan
        messages = [
            {"role": "user", "content": planning_prompt}
        ]

        try:
            logger.info(f"[PLANNER] Creating plan for: '{user_message[:100]}...'")
            logger.debug(f"[PLANNER] System prompt length: {len(system_prompt)}")
            logger.debug(f"[PLANNER] Planning prompt: {planning_prompt[:200]}...")

            response = await self.llm.complete_chat(
                messages=messages,
                system_prompt=system_prompt,
                temperature=0.1,
                max_tokens=2048
            )

            logger.info(f"[PLANNER] Got LLM response: {response.tokens_used} tokens")
            logger.debug(f"[PLANNER] Raw response content:\n{response.content[:500]}...")

            # Parse response
            content = response.content.strip()

            # Extract JSON from response
            plan_data = self._extract_json(content)

            if not plan_data:
                logger.warning(f"[PLANNER] Failed to extract JSON from response")
                logger.debug(f"[PLANNER] Full response content:\n{content}")
                # Fallback: create a simple response plan
                return ExecutionPlan(
                    reasoning="Unable to parse plan, providing direct response",
                    steps=[],
                    requires_confirmation=False
                )

            logger.info(f"[PLANNER] Successfully parsed plan with {len(plan_data.get('plan', plan_data.get('steps', [])))} steps")
            logger.debug(f"[PLANNER] Plan data: {json.dumps(plan_data, indent=2)[:300]}...")

            plan = ExecutionPlan.from_dict(plan_data)

            # Validate and adjust plan
            plan = self._validate_plan(plan)

            logger.info(f"[PLANNER] Plan validated: {len(plan.steps)} steps, confirmation={plan.requires_confirmation}")
            return plan

        except Exception as e:
            logger.error(f"[PLANNER] Error creating plan: {type(e).__name__}: {e}")
            logger.exception(f"[PLANNER] Full traceback:")
            return ExecutionPlan(
                reasoning=f"Error creating plan: {e}",
                steps=[],
                requires_confirmation=False
            )

    def _extract_json(self, content: str) -> Optional[dict]:
        """Extract JSON from LLM response."""
        logger.debug(f"[PLANNER] Attempting to extract JSON from {len(content)} chars")

        # Try direct parse
        try:
            result = json.loads(content)
            logger.debug(f"[PLANNER] Direct JSON parse successful")
            return result
        except json.JSONDecodeError as e:
            logger.debug(f"[PLANNER] Direct JSON parse failed: {e}")

        # Try to find JSON in content
        import re
        json_match = re.search(r'\{[\s\S]*\}', content)
        if json_match:
            try:
                result = json.loads(json_match.group())
                logger.debug(f"[PLANNER] Regex JSON extraction successful")
                return result
            except json.JSONDecodeError as e:
                logger.debug(f"[PLANNER] Regex JSON parse failed: {e}")

        # Try removing markdown code blocks
        if "```" in content:
            logger.debug(f"[PLANNER] Trying to extract from code block")
            lines = content.split("\n")
            json_lines = []
            in_block = False
            for line in lines:
                if line.strip().startswith("```"):
                    in_block = not in_block
                elif in_block:
                    json_lines.append(line)

            if json_lines:
                try:
                    result = json.loads("\n".join(json_lines))
                    logger.debug(f"[PLANNER] Code block extraction successful")
                    return result
                except json.JSONDecodeError as e:
                    logger.debug(f"[PLANNER] Code block JSON parse failed: {e}")

        logger.warning(f"[PLANNER] All JSON extraction methods failed")
        return None

    def _validate_plan(self, plan: ExecutionPlan) -> ExecutionPlan:
        """Validate and adjust execution plan."""
        valid_steps = []

        for step in plan.steps:
            # Check if tool exists
            if self.tool_registry.has_tool(step.tool):
                # Validate parameters against schema
                schema = self.tool_registry.get_schema(step.tool)
                if schema:
                    # Basic validation - could be more thorough
                    valid_steps.append(step)
                else:
                    valid_steps.append(step)
            else:
                logger.warning(f"Unknown tool in plan: {step.tool}")

        plan.steps = valid_steps

        # Check if confirmation is needed
        destructive_tools = [
            "filesystem.delete", "filesystem.move", "filesystem.write",
            "system.shutdown", "system.restart", "system.update"
        ]

        for step in plan.steps:
            if step.tool in destructive_tools:
                plan.requires_confirmation = True
                if not plan.confirmation_message:
                    plan.confirmation_message = f"This action will use {step.tool}. Continue?"
                break

        return plan

    async def synthesize_response(
        self,
        user_message: str,
        plan: ExecutionPlan,
        results: list[ToolResult]
    ) -> str:
        """
        Synthesize a user-friendly response from execution results.

        Args:
            user_message: Original user request
            plan: The execution plan that was followed
            results: Results from each tool execution

        Returns:
            Natural language response for the user
        """
        logger.info(f"[PLANNER] Synthesizing response for {len(results)} results")

        # If no tools were executed, generate direct response
        if not results:
            logger.debug(f"[PLANNER] No tools executed, generating direct response")
            messages = [{"role": "user", "content": user_message}]
            response = await self.llm.complete_chat(
                messages=messages,
                temperature=0.3,
                max_tokens=1024
            )
            logger.info(f"[PLANNER] Direct response generated: {len(response.content)} chars")
            return response.content.strip()

        # Build synthesis prompt
        results_json = json.dumps([r.to_dict() for r in results], indent=2)

        synthesis_prompt = SYNTHESIS_PROMPT.format(
            user_message=user_message,
            plan_json=json.dumps(plan.to_dict(), indent=2),
            results_json=results_json
        )

        logger.debug(f"[PLANNER] Synthesis prompt length: {len(synthesis_prompt)}")
        messages = [{"role": "user", "content": synthesis_prompt}]

        try:
            logger.debug(f"[PLANNER] Requesting synthesis from LLM...")
            response = await self.llm.complete_chat(
                messages=messages,
                temperature=0.3,
                max_tokens=1024
            )
            content = response.content.strip() if response and response.content else ""
            
            if not content:
                logger.warning(f"[PLANNER] Empty response from LLM synthesis")
                return "✓ Task completed successfully (No description provided by Agent)."

            logger.info(f"[PLANNER] Synthesis complete: {len(content)} chars")
            logger.debug(f"[PLANNER] Response preview: {content[:200]}...")
            return content

        except Exception as e:
            logger.error(f"[PLANNER] Error synthesizing response: {type(e).__name__}: {e}")
            logger.exception(f"[PLANNER] Synthesis error traceback:")

            # Fallback: basic result summary
            success_count = sum(1 for r in results if r.success)
            total_count = len(results)

            if success_count == total_count:
                return f"✓ Completed {total_count} operation(s) successfully."
            else:
                return f"Completed {success_count}/{total_count} operations. Some errors occurred."

    async def refine_plan(
        self,
        plan: ExecutionPlan,
        error: str,
        context: Any
    ) -> ExecutionPlan:
        """
        Refine a plan based on execution errors.

        Args:
            plan: The original plan
            error: Error that occurred
            context: Current system context

        Returns:
            Refined execution plan
        """
        refinement_prompt = f"""The following plan encountered an error:

Plan: {json.dumps(plan.to_dict(), indent=2)}

Error: {error}

Please provide a refined plan that addresses this error. Respond with the same JSON format."""

        messages = [{"role": "user", "content": refinement_prompt}]

        try:
            response = await self.llm.complete_chat(
                messages=messages,
                temperature=0.1,
                max_tokens=2048
            )

            plan_data = self._extract_json(response.content)
            if plan_data:
                return ExecutionPlan.from_dict(plan_data)

        except Exception as e:
            logger.exception(f"Error refining plan: {e}")

        return plan

